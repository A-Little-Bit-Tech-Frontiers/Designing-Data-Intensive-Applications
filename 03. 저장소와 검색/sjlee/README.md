관계형 데이터베이스와 NoSQL 저장소에 사용되는 엔진에 대해 알아본다. 

# 1. 데이터베이스를 강력하게 만드는 구조

<img width="553" height="230" alt="image" src="https://github.com/user-attachments/assets/98d2be97-41eb-4a2b-ac91-aeab534d366e" />


위와 같이 키-값 저장소를 두 개의 함수로 구현한 데이터베이스가 있다고 가정하자. `db_set key value`를 통해 데이터베이스에 키와 값을 저장할 수 있다. 키와 값은 어떤 것이든 가능하다. 값에 json 문서가 들어갈 수도 있다.

`db_get key`를 호출하면 해당 키와 연관된 가장 최근 값을 찾아 반환할 수 있다.

<img width="652" height="193" alt="image" src="https://github.com/user-attachments/assets/666406e7-f75d-407d-a09f-d605136f9022" />


기본적인 저장소 형식은 매우 간단하다. 매 라인마다 쉼표로 구분된 키-값 쌍을 포함한 텍스트 파일이다.
`db_set`을 호출할 때마다 파일의 끝에 추가하므로 키를 **여러 번 갱신해도 값의 예전 버전을 덮어 쓰지 않는다.**

⇒ 최신 값을 찾기 위해서는 파일에서 키의 마지막 항목을 봐야 한다.

<img width="633" height="273" alt="image" src="https://github.com/user-attachments/assets/45b60b3d-4225-4360-8d2d-97976bee415b" />


일반적으로 파일 추가 작업은 매우 효율적이기 때문에 `db_set` 함수는 (간단한 경우) 꽤 좋은 성능을 보인다. 
**많은 데이터베이스는 이런 식의 append-only 데이터 파일인 로그를 많이 사용**한다. 

반면 `db_get` 함수는 레코드가 많을 수록 성능이 안좋아진다. 매번 키를 찾을 때마다 O(n) 만큼의 검색 비용이 들기 때문이다. 

데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 **색인**이라는 데이터 구조가 필요하다. 

색인은 기본 데이터에서 파생된 추가적인 구조다. 데이터베이스 내용에는 영향을 미치지 않고, 단지 질의 성능에만 영향을 주는 것이다. (물론, 쓰기 과정에서의 오버헤드는 발생한다.)

## 1.1 해시 색인

디스크 상의 데이터를 색인하기 위해 인메모리 구조를 사용하면?

<img width="644" height="275" alt="image" src="https://github.com/user-attachments/assets/3e3e490c-c09c-4467-8d93-830274208510" />


앞의 예제처럼 단순히 파일에 추가하는 방식으로 데이터 저장소가 구성된다면, 색인 전략은 아래와 같이 가져갈 수 있다.

- 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지하는 전략
- 새로운 키-값 쌍을 추가할 때마다 방금 기록한 데이터의 오프셋을 해시맵에 반영해줘야 한다.

⇒ 이 방식은 비트캐스크가 근본적으로 사용하는 방식이라고 함.

비트캐스크 예시

- 해시 맵을 전부 메모리에 유지한다고 한다.
- 값은 한 번의 디스크 탐색으로 적재할 수 있기 때문에 사용 가능한 메모리보다 더 많은 공간을 사용할 수 있다.

비트캐스크 같은 저장소 엔진은 각 키의 값이 자주 **갱신**되는 상황에 매우 적합하다. 

예를 들어, `key: 동영상 URL / value: 동영상 재생 횟수` 라고 가정하자.
이런 유형의 작업부하에서는 쓰기가 아주 많지만 고유 키는 많지 않다. ⇒ 즉, 키당 쓰기 수는 많지만 메모리에 모든 키를 보관할 수 있다.

근데, 어찌됐든 append-only 방식이면 언젠가 디스크 공간은 부족해질 것이다. 
⇒ 특정 크기의 세그먼트로 로그를 나누는 방식이 좋은 해결책이다.
⇒ 세그먼트가 다 차게되면, 새로운 세그먼트 파일에 이후 쓰기를 수행한다.

<img width="600" height="218" alt="image" src="https://github.com/user-attachments/assets/bdf69932-9e78-4b66-a1cc-b2e25deb8759" />


그리고, 세그먼트 파일들에 대해 컴팩션을 수행할 수도 있다. 

<img width="556" height="270" alt="image" src="https://github.com/user-attachments/assets/9714df83-59da-4057-a9a7-05429cc22c72" />


더 나아가 컴팩션과 동시에 여러 세그먼트를 병합할 수도 있게된다. 세그먼트가 쓰여진 후에는 절대 변경할 수 없기 때문에 병합할 세그먼트는 새로운 파일로 만든다.
⇒ 고정된 세그먼트의 병합과 컴팩션은 백그라운드 스레드에서 수행할 수 있다. 

⇒ 각 세그먼트는 `키-파일 오프셋` 을 가진 자체 인메모리 해시 테이블을 갖는다.

위 방식으로 구현하려면 몇 가지 문제를 고려해야 한다.

- **파일 형식:** 원시 문자열을 부호화하는 바이너리 형식을 사용하면 좋다.
- **레코드 삭제:** 키와 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드를 추가해야 한다. 로그 세그먼트가 병합될 때, 삭제된 키의 이전 값을 무시하게 된다.
- **고장(Crash) 복구:** 데이터베이스의 인메모리 해시 맵은 휘발성이다. 재시작될 때, 전체 세그먼트를 처음부터 끝까지 읽으면서 각 키에 대한 최신 값의 오프셋을 확인하며 해시 맵을 복원하면 된다. 
→  이는 너무 오래걸리므로, 스냅샷을 디스크에 저장해두는 전략도 있다.
- **부분적으로 레코드 쓰기:** 데이터베이스는 로그에 레코드를 추가하다가 죽을 수도 있다. 파일에 체크섬을 포함해 로그의 손상 부분을 탐지하는 전략도 있다.
- **동시성 제어**: 쓰기를 엄격하게 순차적으로 추가한다면 단일 쓰기 스레드를 이용할 수 있다. 데이터 파일 세그먼트는 추가 전용이거나 불변이므로 다중 스레드로 동시에 읽을 수 있다.

추가 전용 로그가 낭비처럼 보일 수 있지만, 아래와 같은 관점에서 보면 좋은 설계다.

- **세그먼트 병합(Compaction)**:
    
    추가와 세그먼트 병합은 순차적인 쓰기 작업이므로 무작위 쓰기보다 훨씬 빠르다.
    자기 회전 디스크(HDD)뿐 아니라 SSD에서도 순차 쓰기가 더 유리하다.
    
- **고장 복구 용이성**:
    
    세그먼트 파일은 **추가 전용**이므로 불변(immutable)이다. (덮어쓰기 X) 
    따라서 쓰는 도중 DB가 죽더라도 이전 값과 새로운 값을 포함한 파일이 남기 때문에 복구가 단순하다.
    
- **데이터 조각화 방지**:
    
    오래된 세그먼트를 주기적으로 병합하면 조각화된 데이터 파일 문제를 피할 수 있다.
    

하지만, 아래와 같은 제약도 있다.

- **해시 테이블의 한계 (메모리 저장)**:
    - 해시 테이블은 메모리에 저장해야 하므로 키가 지나치게 많으면 문제가 된다.
    - 원칙적으로 디스크에도 해시 맵을 유지할 수는 있으나, 무작위 I/O가 많이 발생해 성능이 떨어진다.
    - 디스크 접근이 빈번할 경우 확장 비용이 비싸지므로 충돌 해소를 위한 성가신 로직이 필요하다.
- **해시 테이블과 범위 질의(Range Query) 한계**:
    - 해시 테이블은 범위 질의에 비효율적이다.
    - 예: `kitty00000` ~ `kitty99999` 사이 키들을 쉽게 스캔할 수 없고, 모든 키를 직접 조회해야 한다.

## 1.2 SS 테이블과 LSM 트리

<img width="538" height="234" alt="image" src="https://github.com/user-attachments/assets/a5ddef26-af67-444d-9c4b-55a738a65674" />


위 로그 구조화 저장소 세그먼트는 `키-값` 쌍의 연속이다. 여기서 만약 키-값 쌍을 **키로 정렬**해야 한다면?

이처럼 키로 정렬된 형식을 **정렬된 문자열 테이블(Sorted String Table)** 이라고 부른다. 
SS 테이블은 해시 색인을 가진 로그 세그먼트보다 몇 가지 큰 장점을 가진다.

1. 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적이다. 
    
    <img width="483" height="300" alt="image" src="https://github.com/user-attachments/assets/057107c9-90cc-4c64-a165-2fae30249640" />

    
    위와 같이 병합 정렬을 통해 새로운 병합 세그먼트 파일을 생성한다.
    

1. 파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다.
    
    <img width="532" height="250" alt="image" src="https://github.com/user-attachments/assets/87f1edaa-a372-4bb7-82bf-6496b22ec794" />

    
    위 이미지와 같이 범위 스캔을 하면 된다. 
    

1. 읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축한다. (위 그림에서 음영 부분)
⇒ 그러면 희소 인메모리 색인의 각 항목은 압축된 블록의 시작을 가리키게 된다. 디스크 공간을 줄이기도 하지만 I/O 대역폭 사용도 줄인다.

### 1.2.1 SS 테이블 생성과 유지

데이터를 키로 정렬하려면 어떻게 해야 할까? 

디스크 상에서 B-Tree 등과 같은 자료구조로 정렬된 구조를 유지하곤 하지만 메모리에 유지하는 편이 훨씬 쉽다.

레드 블랙 트리(red-black tree)나 AVL 트리와 같은 구조를 사용하는 것이다. 

- 쓰기가 들어오면 인메모리 균형 트리 데이터 구조에 추가한다. 이 인메모리 트리는 **멤테이블(memtable)**이라고도 한다.
- 멤테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS 테이블 파일로 디스크에 기록한다.
→ 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있는 덕분에 효율적으로 수행 가능.
→ 새로운 SS 테이블 파일은 데이터베이스의 가장 최신의 세그먼트가 된다. 이 기록 과정동안의 쓰기는 새로운 멤테이블 인스턴스에 기록한다.
- 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾고 → 디스크 상의 가장 최신 세그먼트를 찾는다. → 그 다음으로 최신 세그먼트, …. 순으로 조회
- 백그라운드에서 세그먼트 컴팩션은 일어난다.

만약, 데이터베이스가 고장나서 아직 디스크로 기록되지 않은 멤테이블 데이터가 유실된다면?
⇒ 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크 상에 유지해야 한다. 

### 1.2.2 SS 테이블에서 LSM 트리 만들기

원래 이 색인 구조는 **로그 구조화 병합 트리(Log-Structured Merge-Tree)**란 이름으로 패트릭 오닐 등이 발표함.

정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 **LSM 저장소 엔진**이라 부른다.

- 예시
    
    루씬(Lucene)은 전문 검색 엔진이다. 검색 질의가 들어오면 단어가 언급된 모든 문서를 찾는다. 이 접근법은 키를 “단어”로, 값은 “단어를 포함한 모든 문서의 ID목록”으로 하는 `키-값` 구조로 구현한다. 
    
    루씬에서 용어와 포스팅 목록의 매핑은 SS 테이블 같은 정렬 파일에 유지하고 필요에 따라 백그라운드에서 병합한다.
    

### 1.2.3 성능 최적화

- **불필요한 디스크 접근 최소화**: 존재하지 않는 키를 빠르게 판별하기 위해 **블룸 필터**를 사용 → 쓸데없는 세그먼트 읽기를 줄임.
- **압축/병합 전략**:
    - **크기 계층(compaction)**: 작은 SS 테이블을 모아서 큰 SS 테이블로 병합.
    - **레벨(compaction)**: SS 테이블을 크기/범위별로 나누고 오래된 데이터는 더 낮은 레벨로 이동. 디스크 공간을 효율적으로 사용.
- LSM 트리의 기본 원리는 백그라운드에서 **연쇄적으로 SS 테이블을 지속적으로 병합하는 것.**
    - 이 개념은 데이터셋이 가능한 메모리보다 훨씬 더 크더라도 효과적이다.
    - 데이터가 정렬된 순서로 저장돼 있다면 범위 질의를 효율적으로 실행할 수 있다.
    - 이 접근법의 디스크 쓰기는 순차적이라서 LSM 트리가 매우 높은 쓰기 처리량을 보장한다.

## 1.3 B 트리

<img width="627" height="306" alt="image" src="https://github.com/user-attachments/assets/a90eb148-861d-47e2-99d6-bd3c1f3660e9" />


B 트리의 루트부터 리프노드까지 구성된다.

- 최종적으로 개별 키를 포함하는 페이지는 리프 노드다. 이 페이지는 각 키의 값을 포함하거나 값을 찾을 수 있는 페이지 참조를 포함한다.
- B 트리의 한 페이지에서 하위 페이지를 참조하는 수를 **분기 계수(branching factor)**라고 부른다.
위 예제에서는 6이다.
- 이 알고리즘은 계속 균형을 유지하므로 비용은 항상 O(log n)이다.

### 1.3.1 신뢰할 수 있는 B 트리 만들기

**B-트리의 기본 동작**

- 새로운 데이터를 디스크 페이지에 **덮어쓰기** 하는 방식으로 저장한다.
- 페이지의 위치가 바뀌지 않고, 변경된 부분만 덮어쓴다.
- 이는 LSM 트리와 같은 **로그 구조 저장 방식**과 큰 차이점.

**쓰기 작업 시, 문제점과 해결책**

- 여러 페이지를 동시에 갱신해야 하는 경우가 많다.
- 예) 상위 노드 분할 시 두 개의 하위 노드와 참조를 모두 수정해야 함.
- 일부 페이지만 기록하다 고장이 나면 **고아 페이지(orphan page)** 발생 위험.
    - 고아 페이지: 부모와 연결되지 않은 페이지.

이와 같은 문제를 방지하고자 write-ahead 방식으로 로그를 기록함. 

- B-트리 갱신 전에 **변경 내역을 별도 로그 파일**에 기록.
- 데이터베이스 고장 후 복구 시 이 로그를 사용해 트리를 **일관된 상태로 복원**.
- 이 방식으로 쌓은 로그가 **redo log**

**다중 스레드가 B-트리에 접근하는 동시성을 제어**

- 여러 스레드가 동시에 B-트리에 접근하면 **동기화 제어** 필요.
- 보통 **래치(latch, 가벼운 잠금)**를 사용해 데이터 구조 보호.
- 동기화 제어를 소홀히 하면 트리 구조가 깨질 수 있음.

### 1.3.2 B 트리 최적화

1. **쓰기 방식 최적화**

- WAL 대신 COW(copy-on-write) 방식 사용 가능 (예: LMDB).
- 변경된 페이지를 새로운 위치에 기록하고, 상위 페이지의 새로운 버전을 만들어 참조를 교체.
- 장점: 동시성 제어에 유용, WAL 기록 오버헤드 감소.

---

2. **키 저장 최적화**

- 페이지에 전체 키를 저장하지 않고, **경계 값(boundary values)**만 저장해도 충분.
- 트리 깊이를 줄일 수 있고, 전체 저장 공간도 절약 가능.

---

3. **페이지 배치 최적화**

- 이상적으로는 **인접한 키 범위의 페이지들이 디스크 상에서도 가깝게** 위치해야 효율적.
- 하지만 디스크 쓰기 특성상 항상 순서를 유지하기 어려움.
- B 트리는 리프 노드 페이지들을 디스크에 연속 배치하려 시도하지만, 크기가 커지면 한계가 있음.
- 반면 **LSM 트리**는 대규모 병합 과정에서 자동으로 연속된 순서를 유지하기 쉬움.

---

4. **포인터 추가**

- 각 리프 페이지에 **양쪽 형제 페이지에 대한 참조**를 추가.
- 상위 페이지를 다시 탐색하지 않고도 순차적으로 키를 스캔 가능.

---

5. **프랙탈 트리(Fractal Tree)**

- 로그 구조 최적화를 빌려온 변형 기법.
- 디스크 접근 횟수를 줄이기 위해 고안.
- 수학적 프랙탈과는 관련 없음.

### 1.3.3 LSM 트리의 장점

B 트리 색인은 두 번 기록해야 한다. 쓰기 전 로그와 트리 페이지에 한 번씩.

로그 구조화 색인도 SS 테이블의 반복된 컴팩션과 병합으로 인해 여러 번 데이터를 다시 쓴다. 데이터베이스에 쓰기 한 번이 (데이터베이스 수명동안) 여러 번의 쓰기로 이어지는 현상을 **쓰기 증폭**이라 한다. 
쓰기가 많은 애플리케이션에서 성능 병목은 디스크에 쓰는 속도일 것이다. 그리고, 쓰기 증폭은 성능 비용이다. 저장소 엔진이 디스크에 기록할수록 디스크 대역폭 내 처리할 수 있는 초당 쓰기는 점점 줄어든다.

LSM 트리는 아래와 같은 이유로 B 트리보다 쓰기 처리량을 높게 유지할 수 있다.

- 트리에서 여러 페이지를 덮어 쓰는게 아니라 순차적으로 컴팩션된 SS 테이블 파일을 쓰기 때문이다.
- 압축률이 더 좋아, B 트리에 비해 디스크에 더 적은 파일을 생성한다.
B 트리 저장소 엔진은 파편화로 인해 사용하지 않는 디스크 공간 일부가 남는다.

### 1.3.4 LSM 트리의 단점

디스크에서 컴팩션 연산이 끝날 때까지 요청을 대기해야 할 수 있다. 처리량과 평균 응답 시간이 성능에 미치는 영향은 대개 작지만, 상위 백분위 질의의 응답시간을 기준으로 하면 때때로 길다.
반면 B 트리 성능은 로그 구조화 저장소 엔진보다 예측하기 쉽다.

디스크의 쓰기 대역 폭은 유한하다. 근데, 로깅 & 멤테이블을 디스크로 방출 & 백그라운드에서 수행되는 컴팩션 스레드가 이 대역폭을 공유해야 한다. → 컴팩션을 위해 점점 더 많은 대역폭이 필요하다.

B 트리의 장점은 각 키가 색인의 한 곳에만 존재한다는 것이다. 반면, 로그 구조화 저장소 엔진은 다른 세그먼트에 같은 키의 복사본이 있을 수 있다. 
⇒ 이런 측면 때문에 강력한 트랜잭션 시맨틱을 제공하는 데이터베이스에는 B 트리가 훨씬 매력적이다.

### 1.3.5 기타 색인 구조

1. **기본기(Primary Key) 색인**

- 관계형 DB: 테이블의 기본키(primary key)에 대해 색인 생성.
- 문서 DB: 각 문서 ID를 기준으로 색인.
- 기본키 색인은 **레코드를 유일하게 식별**하는 기준.

---

2. **보조 색인(Secondary Index)**

- **추가적인 색인**으로 효율적 조인을 지원.
- 예: `user_id` 컬럼 색인 → 사용자별 레코드 조회 빠르게 가능.
- 단점: 키가 중복될 수 있음.
    - 해결 방법: (1) 레코드 식별자 리스트 추가, (2) 키+식별자 조합으로 고유화.
- B-트리, 로그 구조 색인 방식 모두 활용 가능.

---

3. **값 저장 방식**

- 색인은 키 중심이지만 실제 데이터(값)도 포함할 수 있음.
- **힙 파일(Heap File)**
    - 색인에서 값 대신 참조를 저장, 실제 데이터는 별도 파일에 기록.
    - 장점: 데이터 중복 피할 수 있음.
- **클러스터드 색인(Clustered Index)**
    - 색인 안에 데이터 직접 저장.
    - MySQL InnoDB: 기본키 클러스터드 색인 필수.
    - MS SQL Server: 테이블당 하나 지정 가능.
- **커버링 색인(Covering Index)** / **Index with Included Column**
    - 일부 컬럼 값을 색인 안에 포함 → 쿼리를 색인만으로 처리 가능.

---

4. **다중 칼럼 색인**

- 하나의 키가 여러 칼럼(컬럼 조합)에 해당.
- **결합 색인(Concatenated Index)**
    - (성, 이름) 같이 여러 필드 결합.
    - 특정 성+이름 조합 탐색은 효율적이지만, 이름 단독 검색에는 한계.
- **다차원 색인(Multi-dimensional Index)**
    - 예: 위치 기반 서비스에서 위도(latitude), 경도(longitude) 동시에 색인.
    - 일반 B-트리/LSM 트리는 비효율적 → R-트리 같은 공간 색인 필요.
- 응용: 색인에 시간, 색상(빨강, 초록 등) 같은 다차원 정보 포함 가능.

---

5. **전문 검색(Full-text Search) & 퍼지(Fuzzy) 색인**

- 단순한 키 매칭이 아닌 **유사한 값 검색**을 지원.
- **퍼지 색인**: 철자가 틀리거나 비슷한 단어 검색 지원.
    - 루씬(Lucene): 편집 거리(Edit Distance) 기반 검색.
    - 오토마톤(Automaton), 트라이(Trie), Levenshtein Automaton 등 활용.
- 문서 검색, 추천 시스템, 자연어 처리(NLP)와 결합.

# 2. 트랜잭션 처리나 분석?

<img width="636" height="182" alt="image" src="https://github.com/user-attachments/assets/7796669c-0aee-4624-9808-c96a85d715ba" />


- OLTP(Online Transaction Processing), OLAP(Online Analytic Processing)
- 트랜잭션 처리(OLTP)는 주로 비즈니스 거래(급여 지급, 판매, 주문 등) 같은 **실시간 짧은 질의와 빠른 쓰기** 에 최적화된 시스템으로, ACID 특성을 반드시 보장한다.
- 반면 분석 처리(OLAP)는 **데이터를 집계·요약**하여 경영 의사결정을 지원하는 데 초점을 두며, 대량의 데이터를 읽고 계산하는 작업을 의미한다.
- OLTP는 최신 상태의 데이터를 다루고, OLAP은 시간에 따른 이벤트 이력과 패턴 분석을 수행한다.

이 차이 때문에 기업들은 트랜잭션 DB와 별도로 분석 전용 DB(데이터 웨어하우스)를 운영하게 되었다.

## 2.1 데이터 웨어하우징

<img width="503" height="336" alt="image" src="https://github.com/user-attachments/assets/c61133e1-519e-4ae1-a88f-8058de0825b3" />


- 대규모 기업은 여러 **OLTP 시스템**(판매 관리, 재고 관리, 인사 등)을 운영하며, 이는 실시간 트랜잭션 처리에 최적화되어 높은 가용성과 낮은 지연을 요구한다.
- 하지만 OLTP DB에서 직접 분석 질의(ad-hoc query)를 실행하면 많은 데이터를 스캔해야 하므로 비용이 크고 성능 저하를 초래할 수 있다.
- **데이터 웨어하우스**는 분석 전용 DB로, OLTP에서 데이터를 추출(Extract) → 변환(Transform) → 적재(Load)하여(ETL) 분석 친화적 형태로 저장한다.
- 대기업은 대부분 데이터 웨어하우스를 보유하지만, 소규모 기업은 소량 데이터만 다루므로 SQL DB나 스프레드시트로도 분석이 가능하다.
- 요약하자면, **OLTP는 트랜잭션 처리**, **데이터 웨어하우스는 분석 최적화**에 각각 특화된 구조다.

OLTP 데이터베이스와 데이터 웨어하우스의 차이는 아래와 같다.

- **둘 다 SQL 인터페이스**를 제공하지만, **질의 패턴 최적화 방식이 다르다**.
    - OLTP: 실시간 트랜잭션 처리에 초점.
    - 데이터 웨어하우스: 대규모 분석(드릴 다운, 슬라이싱/다이싱 등)에 최적화.
- 일부 DB 제품(MS SQL, SAP HANA)은 **OLTP와 DW를 함께 지원**하지만, 보통은 분리 운영.

## 2.2 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마

<img width="479" height="426" alt="image" src="https://github.com/user-attachments/assets/bf022b7d-62d5-49e9-b15a-a4bff659e67a" />


OLTP 영역에서 데이터 모델은 광범위하고 다양하게 사용되는 반면에 OLAP 에서는 데이터 모델의 다양성이 훨씬 적다. ⇒ 많은 데이터 웨어하우스는 별 모양 스키마(star schema)로 알려진 정형화 방식을 사용한다.

### 1. **별 모양 스키마(Star Schema)**

- 데이터 웨어하우스에서 흔히 사용하는 차원 모델링 방식.
- **사실 테이블(Fact Table)**: 사건/거래 데이터를 기록 (예: `fact_sales`).
- **차원 테이블(Dimension Table)**: 사건을 설명하는 맥락 제공 (예: 제품, 고객, 매장, 날짜, 프로모션 등).
- 사실 테이블의 각 행 = 개별 이벤트 (누가, 언제, 어디서, 무엇을, 어떻게, 왜).
- 장점: 구조 단순, 쿼리 효율적, 직관적.

---

### 2. **눈꽃송이 스키마(Snowflake Schema)**

- 별 모양 스키마의 변형.
- 차원 테이블을 더 세분화해 하위 차원으로 분리 (예: 제품 테이블 → 브랜드 테이블 참조).
- **장점**: 더 정규화되어 중복 최소화.
- **단점**: 구조가 복잡해져 쿼리 난이도 증가.

**⇒ 별 모양 스키마는 직관적이고 분석에 자주 쓰이고**, **눈꽃송이 스키마는 더 정규화되어 있지만 복잡**하다는 차이가 있다.

# 3. 컬럼 지향 저장소

- **배경**
    - `사실 테이블`은 수십~수백 억 건 이상의 행(row)과 수백 개 이상의 칼럼(column)을 가짐.
    - 하지만 분석 질의는 보통 몇 개 칼럼만 접근 → 모든 칼럼을 로우 단위로 읽는 **로우 지향(Row-oriented)** 저장 방식은 비효율적.
- **로우 지향 방식의 한계**
    - OLTP DB에서처럼 모든 값을 로우 단위로 함께 저장.
    - 분석 질의(예: 특정 연도/제품군의 합계 계산)를 하려면 필요 없는 칼럼까지 전부 읽어야 함 → 속도 저하.
- **칼럼 지향 저장소 방식**
    - 각 칼럼을 따로 파일/저장소에 저장.
    - 질의 시 필요한 칼럼만 읽기 때문에 **입력/출력(IO) 감소, 성능 향상**.
    - 예: Parquet, Google Dremel 기반 시스템.
    - 로우 전체를 재구성하려면 같은 인덱스(행 번호)의 칼럼 값을 모아 결합.
- **장점**
    - 대규모 데이터 웨어하우스 분석에 최적.
    - SUM, AVG, COUNT 같은 집계 쿼리에서 효율적.
    - 압축률도 높아 저장 공간 절약 가능.

<img width="630" height="465" alt="image" src="https://github.com/user-attachments/assets/24b10c62-3930-4748-8e7d-c2bb1150dc9b" />


- **분석 쿼리 최적화**:
    
    예를 들어 “2013년에 과일과 사탕을 얼마나 팔았는가?” 같은 쿼리를 실행할 때,
    
    `date_key`, `product_sk`, `quantity`만 읽으면 됨 → 나머지 칼럼 무시 가능.
    
- 따라서 **디스크 I/O를 크게 줄이고 빠르게 분석** 가능.
- `SELECT *` 같은 전체 로우 읽기는 거의 필요 없고, 필요한 칼럼만 조회.
- 만약 결과를 원래의 로우 형태로 다시 보여줘야 한다면,
    
    **같은 인덱스(행 번호)**의 값들을 모아 하나의 레코드(Row)로 조립.
    
- 예를 들어 각 칼럼 파일의 "23번째 값"을 모으면 원래 테이블의 23번째 행을 재구성할 수 있음.

## **3.1 칼럼 압축**

- 칼럼 단위 데이터는 값이 반복되기 때문에 **압축 효율이 매우 높음**.
- 대표 방식:
    - **비트맵 부호화(Bitmap Encoding)**: 각 고유 값을 비트맵으로 표현해 질의 시 빠르게 계산.
    - **런-렝스 부호화(Run-Length Encoding)**: 연속된 같은 값의 개수만 기록.

## 3.2 **칼럼 저장소의 순서 정렬**

- 로우 삽입 순서와 무관하게 **쿼리 효율을 높이도록 칼럼을 정렬**할 수 있음.
- 예: `date_key`로 먼저 정렬 → 같은 날짜의 데이터가 묶임.
- 같은 그룹 내에서 `product_sk`로 2차 정렬 → 특정 날짜에 어떤 상품이 많이 팔렸는지 빠르게 집계 가능.
- **여러 차원으로 정렬하면 집계·압축 효율 모두 향상**.

## **3.3 컬럼 지향 저장소에 쓰기**

- 컬럼 지향 저장소는 **쓰기(update-in-place)**가 어렵다.
- 새로운 데이터 삽입 시 전체 칼럼을 재작성해야 하기 때문.
- 해결책:
    - **메모리 버퍼(LSM 트리 유사)**에 먼저 기록하고 일정 주기마다 병합(merge).
    - 최근 쓰기 데이터는 메모리에, 오래된 데이터는 디스크 칼럼 저장소에 저장.

## 3.4 집계: 데이터 큐브와 구체화 뷰

모든 데이터 웨어하우스가 컬럼 저장이 필수는 아니지만, 즉석 분석 질의에 상당히 빠르기 때문에 급속하게 인기를 얻고 있다.

데이터 웨어하우스의 특징으로는 **구체화 집계(materialized aggregate)**가 있다. COUNT, SUM, AVG, MIN, MAX 같은 집계 함수를 처리하기 위해, 이를 캐시하는 방법이다.

이런 캐시를 만드는 한 가지 방법은 **구체화 뷰(materialized view)**다. 관계형 데이터 모델에서는 이런 캐시를 보통 가상 뷰로 정의한다. 구체화 뷰는 **디스크에 기록된 질의 결과의 실제 복사본이지만 가상 뷰는 단지 질의를 작성하는 단축키일 뿐이다.**

⇒ 원본 데이터를 변경하면 구체화 뷰도 갱신해야 한다. 구체화 뷰는 원본 데이터의 비정규화된 복사본이기 때문이다. DB는 이를 자동으로 수행하지만, 이런 갱신으로 인한 쓰기 비용이 만만치 않아서 OLTP 환경에서는 구체화 뷰를 자주 사용하지 않는다.
반면, 데이터 웨어하우스는 읽기 비중이 크기 때문에 구체화 뷰 사용이 합리적이다.

<img width="558" height="296" alt="image" src="https://github.com/user-attachments/assets/c76a9187-159f-4c83-8c0e-6571b88039c4" />


데이터 큐브 또는 OLAP 큐브라고 알려진 구체화 뷰는 좀 일반화된 구체화 뷰의 특별 사례.

위 그림의 product, date처럼 2차원 테이블에만 외래 키를 가진다고 가정해보자. 날짜와 제품을 결합한 집계 쿼리의 결과를 얻을 수도, 각 로우나 컬럼에 해당하는 집계 결과를 바로 얻을 수도 있다.

일반적으로 대개 2차원 이상이다. 

이러한 구체화 데이터 큐브의 장점

- 특정 질의 결과 캐싱으로 인한 질의 속도 향상

단점

- 원시 데이터에 질의하는 것과 동일한 유연성이 없음
- 예를 들어, where 문에 `가격` 추가되면 데이터 큐브에서 조회 불가함. 때문에, 대부분의 데이터 웨어하우스는 가능한 많은 원시 데이터를 유지하기 위해 노력한다.

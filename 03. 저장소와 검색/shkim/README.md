# 저장소와 탐색

이 챕터에서는 데이터베이스의 관점에서 데이터를 어떻게 저장하고, 다시 요청받았을 때 어떻게 찾아낼 수 있는지에 대해 다룹니다. <br>
두 가지 저장 엔진 계열, 즉 로그 구조(storage engines)와 B-트리(page-oriented storage engines) 같은 페이지 지향 저장 엔진을 살펴봅니다.

## 데이터베이스를 움직이는 데이터 구조들

세계에서 가장 단순한 데이터베이스를 두 개의 Bash 함수로 구현한다고 가정해봅시다.

```bash
db_set () { echo "$1,$2" >> database }
db_get () { grep "^$1," database | sed -e "s/^$1,//" | tail -n 1 }
```

`db_set key value`로 키와 값을 데이터베이스에 저장할 수 있고, `db_get key`로 해당 키에 연결된 가장 최근 값을 조회할 수 있습니다. <br>
저장 포맷은 매우 단순합니다. 각 줄에 키와 값이 콤마로 구분되어 저장됩니다. `db_set`을 호출할 때마다 파일 끝에 추가(append)되므로, 키를 여러 번 업데이트하면 이전 값들이 덮어쓰여지지 않고 남아있습니다. 최신 값을 찾으려면 해당 키의 마지막 항목을 찾아야 합니다. <br>
이 방식은 매우 단순하지만, 파일에 추가하는 작업은 일반적으로 매우 효율적입니다. 실제 데이터베이스들도 내부적으로 추가 전용(append-only) 로그 파일을 사용합니다. <br>
특정 키의 값을 효율적으로 찾으려면 인덱스(index)라는 추가적인 데이터 구조가 필요합니다.

> 로그라는 단어는 애플리케이션 로그를 언급할 때 종종 사용되기도 한다. 이때 로그는 애플리케이션에서 무슨 일이 일어났는지 기술한 텍스트를 출력한다. <br>
> 이 책에서 로그는 조금 더 일반적인 의미로 연속된 추가 전용 레코드다.

### 해시 인덱스(Hash Indexes)

<img width="640" height="317" alt="Image" src="https://github.com/user-attachments/assets/0476f577-994e-4109-8a27-0eafa1e2ca79" />

키-값 데이터에 대한 인덱스를 생각해봅시다. <br>
데이터 저장이 파일에 추가하는 방식뿐이라면, 가장 단순한 인덱싱 방법은 모든 키를 데이터 파일의 바이트 오프셋에 매핑하는 인메모리 해시맵을 유지하는 것입니다. <br>
새로운 키-값 쌍을 파일에 추가할 때마다 해시맵도 업데이트합니다. 값을 조회할 때는 해시맵을 통해 오프셋을 찾고, 해당 위치로 이동해 값을 읽습니다. <br>
하지만 파일이 계속 커지면 디스크 공간이 부족해질 수 있습니다. 이를 해결하기 위해 로그를 일정 크기의 세그먼트(segment)로 나누고, 세그먼트가 가득 차면 새 파일로 넘어갑니다. <br>
세그먼트에서는 중복 키를 버리고, 각 키의 최신 값만 남기는 컴팩션(compaction)을 수행합니다. 여러 세그먼트를 병합하면서 동시에 컴팩션을 할 수도 있습니다. (컴팩션은 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미)

<img width="681" height="284" alt="Image" src="https://github.com/user-attachments/assets/028cb809-f203-4113-8e64-13ef334e30bd" /> <br>
<img width="670" height="380" alt="Image" src="https://github.com/user-attachments/assets/fee7ab3f-7527-481d-bbc4-c82491923f55" />

이러한 append-only 설계는 여러 장점이 있습니다:
- 추가 및 병합 작업이 순차적 쓰기이므로 속도가 빠릅니다.
- 세그먼트 파일이 변경 불가능(immutable)이면 동시성 및 장애 복구가 단순해집니다.
- 오래된 세그먼트 병합으로 데이터 파일이 파편화되는 문제를 해결할 수 있습니다.

하지만 해시 인덱스에도 한계가 있습니다:
- 해시 테이블이 메모리에 모두 들어가야 합니다.
- 범위 쿼리가 비효율적입니다. 예를 들어, 특정 범위의 키를 모두 조회하려면 하나하나 해시맵에서 찾아야 합니다.

다음 섹션에서는 이러한 한계를 극복하는 인덱싱 구조를 살펴봅니다.

### SSTable과 LSM-트리

로그 구조 저장 세그먼트는 키-값 쌍의 순서대로 저장됩니다. 최신 값이 우선합니다. <br>
세그먼트 파일 포맷을 조금만 바꿔서, 키-값 쌍을 키 기준으로 정렬하면 SSTable(Sorted String Table)이 됩니다.

SSTable의 장점:

1. 세그먼트 병합이 간단하고, 파일이 메모리보다 커도 효율적으로 병합할 수 있습니다.

<img width="659" height="471" alt="Image" src="https://github.com/user-attachments/assets/b6f59aef-3841-41a5-b75b-754bc0360291" />

2. 특정 키를 찾으려면 모든 키의 인덱스를 메모리에 둘 필요 없이, 정렬된 키의 오프셋만 알면 범위 내에서 빠르게 탐색할 수 있습니다.

<img width="668" height="347" alt="Image" src="https://github.com/user-attachments/assets/484c5cf3-39d5-4d27-9c0c-33647739d91d" />

3. 읽기 요청이 범위 내 여러 키-값을 조회할 때, 블록 단위로 묶어서 압축해 저장할 수 있습니다.

**SSTable 유지 방법**

- 쓰기가 들어오면 인메모리 균형 트리(예: red-black tree)에 저장합니다. 이를 memtable이라 부릅니다.
- memtable이 일정 크기를 넘으면 SSTable 파일로 디스크에 기록합니다.
- 읽기 요청 시, memtable → 최신 디스크 세그먼트 → 오래된 세그먼트 순으로 찾습니다.
- 주기적으로 백그라운드에서 병합 및 컴팩션 작업을 수행해 중복 및 삭제된 값을 정리합니다.

**LSM-트리**

이 알고리즘은 LevelDB, RocksDB 등 다양한 키-값 저장 엔진의 기반이 되며, Cassandra, HBase 등에서도 사용됩니다. Lucene(Elasticsearch, Solr)이 텍스트 검색에 유사한 방법을 사용합니다.

**성능 최적화**

LSM-트리는 Bloom filter를 활용해 불필요한 디스크 읽기를 줄이고, 다양한 병합(compaction) 전략을 사용합니다. 정렬된 데이터 덕분에 범위 쿼리 효율이 높고, 순차적 디스크 쓰기로 대량 쓰기 처리에 강합니다.

### B-트리

<img width="681" height="416" alt="Image" src="https://github.com/user-attachments/assets/680acd6c-98e3-4bfe-a1e4-e457d3639645" />

B-트리는 데이터베이스에서 널리 쓰이는 인덱스 구조입니다. 키-값 쌍을 정렬해 효율적인 조회와 범위 쿼리가 가능합니다. <br>
B-트리는 데이터베이스를 보통 4KB 크기의 고정 블록(페이지)으로 나눕니다. 각 페이지는 주소로 식별되며, 다른 페이지를 참조할 수 있습니다. <br>
업데이트 시 리프 페이지를 찾아 값을 수정하고, 필요하면 페이지 분할을 통해 균형을 유지합니다. B-트리의 깊이는 O(log n)으로, 대규모 데이터베이스에서도 효율적입니다.

<img width="640" height="410" alt="Image" src="https://github.com/user-attachments/assets/5efc2beb-9a71-4af6-8d61-d482655f3815" />

**신뢰성 확보**

B-트리의 주요 쓰기 작업은 페이지 덮어쓰기입니다. 로그 구조 인덱스와 달리 직접 파일을 수정하므로 SSD 등에서 복잡한 하드웨어 작업이 필요합니다. <br>
장애 복구를 위해 B-트리는 Write-Ahead Log(WAL)라는 추가 로그 파일에 변경 내역을 먼저 기록합니다. 장애 발생 시 WAL을 사용해 일관성을 복구합니다. 동시성 제어를 위해 래치(latch)를 사용합니다.

**B-트리 최적화**

- Copy-on-Write: 직접 덮어쓰지 않고, 새로운 위치에 복사해 저장합니다.
- 키 축약: 내부 페이지의 키를 줄여 공간 절약 및 분기 수 증가.
- 디스크 레이아웃 최적화: 리프 페이지를 순차적으로 배치해 쿼리 효율 향상.
- 추가 포인터: 리프 페이지끼리 연결해 순차 스캔을 용이하게 함.
- B-트리 변형: 프랙탈 트리 등 로그 구조 아이디어를 도입해 디스크 탐색 감소.

### B-트리와 LSM-트리 비교

B-트리는 구현이 성숙했고, LSM-트리는 쓰기 성능이 뛰어납니다. LSM-트리는 대량 쓰기에 유리하고, B-트리는 읽기 성능이 우수합니다.

**LSM-트리 장점**

쓰기 작업이 많은 환경에서 LSM-트리가 강점이 있습니다. B-트리는 데이터를 최소 두 번 써야 하므로 SSD에서 쓰기 증폭(write amplification) 문제가 발생합니다.

**LSM-트리 단점**

컴팩션 작업이 읽기/쓰기 작업에 영향을 줄 수 있어, 응답 시간이 일시적으로 증가할 수 있습니다.

### 기타 인덱스 구조

1. 보조 인덱스(Secondary Indexes): 기본 키 외의 컬럼에 효율적인 조회와 조인을 지원합니다.
2. 키-값 인덱스 기반 생성: 보조 인덱스는 키-값 인덱스에서 파생될 수 있습니다.
3. 클러스터드/커버링 인덱스: 클러스터드 인덱스는 데이터 자체를 인덱스에 저장합니다. 커버링 인덱스는 일부 컬럼만 저장해 인덱스만으로 쿼리 처리 가능.
4. 다중 컬럼 인덱싱: 여러 필드를 하나의 키로 결합해 복합 쿼리에 활용합니다.
5. 다차원 인덱싱: R-트리, space-filling curve 등으로 지리정보 및 다양한 범위 데이터 처리.
6. 전체 텍스트/퍼지 인덱싱: 텍스트 검색 엔진은 동의어, 문법 변형, 근접 검색 등을 지원. 퍼지 검색은 오타 처리, Levenshtein automata, 머신러닝 기반 분류 등 활용.
7. 인메모리 데이터베이스: RAM 가격 하락으로 성능 향상. VoltDB, Redis 등이 대표적. 내구성은 스냅샷, 복제, 특수 하드웨어로 보장.
8. 미래 트렌드: 메모리보다 큰 데이터셋을 위한 인메모리 아키텍처, 안티캐싱, 비휘발성 메모리(NVM) 등 미래 저장 엔진 설계 고려.

## 트랜잭션 처리 vs 분석(OLTP vs OLAP)

과거 비즈니스 데이터 처리에서 트랜잭션은 상업 활동을 의미했습니다. 데이터베이스가 확장되면서 용어는 남아있지만 의미가 넓어졌습니다.

**트랜잭션 처리(OLTP, online transaction processing):**

- 대화형 애플리케이션(블로그 글의 댓글, 게임 액션, 주소록의 연락처 등)의 저지연 읽기/쓰기.
- ACID 속성이 필수는 아님.
- 소수의 레코드를 키로 조회하는 패턴.

**분석(OLAP, online analytic processing):**

- 대량의 레코드를 스캔해 집계 통계 계산.
- 비즈니스 분석가가 쿼리 작성.
- 데이터 집계, 보고서 작성 등.

### 데이터 웨어하우징

기업은 다양한 OLTP 시스템을 운영합니다. 각 시스템은 독립적으로 운영되며, 복잡성 때문에 별도 관리팀이 필요합니다.

OLTP 시스템:

- 다수의 시스템이 독립적으로 운영.
- 고가용성, 저지연 트랜잭션 처리.
- 임의 분석 쿼리 실행을 꺼림(성능 저하 위험).

데이터 웨어하우스:

- 분석가가 OLTP에 영향 없이 쿼리 가능.
- 여러 OLTP 시스템의 데이터를 읽기 전용 복사본으로 보관.
- ETL(추출, 변환, 적재) 프로세스 필요.

<img width="691" height="495" alt="Image" src="https://github.com/user-attachments/assets/c2285a3f-01c3-471f-8d24-8a697ad294dc" />

장점:

- 분석 패턴에 최적화.
- 다양한 OLTP 시스템 데이터 통합.
- 트랜잭션 처리에 영향 없이 데이터 탐색 가능.

### 스타와 스노우플레이크: 분석용 스키마

데이터 웨어하우스는 스타 스키마(Star Schema)나 다차원 모델링을 많이 사용합니다.

<img width="669" height="695" alt="Image" src="https://github.com/user-attachments/assets/2d69858f-af89-46df-be42-1c5ac71d951d" />

스타 스키마:

- 중심에 사실 테이블(fact table)이 위치(예: 구매 이벤트).
- 각 행은 개별 이벤트를 나타냄.
- 사실 테이블은 속성과 차원 테이블의 외래키를 포함.
- 차원은 이벤트의 다양한 측면(누가, 무엇을, 어디서, 언제, 어떻게, 왜 등)을 나타냄.

## 컬럼 기반 저장(Column-Oriented Storage)

과제:

- 수조 개의 행, 페타바이트 규모의 사실 테이블 관리.
- 100개 이상의 컬럼을 효율적으로 저장해야 함.

쿼리 최적화:

- 분석 쿼리는 일부 컬럼만 사용하며, 전체 컬럼을 조회하는 경우는 드묾.

```sql
SELECT dim_date.weekday, dim_product.category,
  SUM(fact_sales.quantity) AS quantity_sold
FROM fact_sales
  JOIN dim_date ON fact_sales.date_key = dim_date.date_key
  JOIN dim_product ON fact_sales.product_sk = dim_product.product_sk
WHERE dim_date.year = 2013
  AND dim_product.category IN ('Fresh fruit', 'Candy')
GROUP BY dim_date.weekday, dim_product.category;
```

컬럼 기반 저장:

- 각 컬럼의 값을 별도의 파일에 저장.
- 필요한 컬럼만 읽으므로 처리 시간이 단축됨.
- 관계형뿐 아니라 Parquet 등 비관계형 데이터에도 적용 가능.

효율적 쿼리 실행:

- 인덱스는 전체 행을 처리해야 하지만, 컬럼 저장은 필요한 컬럼만 읽으므로 쿼리 성능이 향상됨.

장점:

- 분석에 최적화, 필요한 컬럼만 우선 처리.
- 불필요한 데이터 로딩 감소로 쿼리 효율 개선.
- 전체 행 재조립도 가능.

### 컬럼 압축(Column Compression)

컬럼 저장은 반복 값이 많아 압축에 유리합니다. 비트맵 인코딩(bitmap encoding) 등 다양한 압축 기법을 사용합니다. 각 값마다 비트맵을 만들어 행의 존재 여부를 1과 0으로 표시합니다.

### 컬럼 저장의 정렬 순서(Sort Order)

컬럼 저장에서는 보통 삽입 순으로 행이 정렬되지만, 인덱싱을 위해 특정 컬럼 기준으로 전체 행을 정렬하면 쿼리 최적화에 도움이 됩니다. 각 컬럼을 독립적으로 정렬하면 행 간 관계가 깨지므로, 행 전체를 기준으로 정렬해야 합니다. <br>
관리자는 쿼리 패턴에 따라 정렬 컬럼을 전략적으로 선택합니다. 예를 들어, date_key로 먼저 정렬하면 특정 날짜 범위 쿼리가 빨라집니다. <br>
정렬 순서는 압축에도 도움이 됩니다. 첫 번째 정렬 키는 값 반복이 많아 런-길이 인코딩(run-length encoding) 등으로 효율적으로 압축할 수 있습니다. C-Store, Vertica 등은 데이터를 여러 정렬 방식으로 저장해 다양한 쿼리 패턴을 지원합니다.

### 컬럼 저장에 쓰기(Write to Column-Oriented Storage)

컬럼 저장, 압축, 정렬 등은 대용량 읽기 쿼리를 빠르게 하지만, 쓰기 작업은 복잡해집니다. B-트리처럼 즉시 수정하기 어렵고, 압축된 컬럼에 행을 삽입하려면 전체 컬럼 파일을 다시 써야 할 수도 있습니다. <br>
LSM-트리 방식처럼, 쓰기는 먼저 인메모리 저장소에 기록한 뒤, 일정량이 쌓이면 디스크 컬럼 파일과 병합해 일괄 저장합니다. Vertica 등에서 활용하는 방식입니다. <br>
쿼리는 디스크 컬럼 데이터와 인메모리 데이터를 모두 고려해 결과를 반환합니다. 쿼리 최적화기가 이를 처리해 사용자는 데이터 수정이 즉시 반영된 것처럼 사용할 수 있습니다.

### 집계: 데이터 큐브와 물리적 뷰

모든 데이터 웨어하우스가 컬럼 저장만 사용하는 것은 아닙니다. 전통적인 행 기반 데이터베이스도 사용됩니다. <br>
자주 사용되는 집계 함수(COUNT, SUM, AVG, MIN, MAX 등)를 매번 계산하는 것은 비효율적이므로, 물리적 뷰(materialized view)를 활용해 쿼리 결과를 실제로 디스크에 저장해 캐시합니다. <br>
물리적 뷰는 데이터가 변경될 때마다 업데이트가 필요하지만, 읽기 중심 데이터 웨어하우스에서는 매우 유용합니다. <br>
데이터 큐브(OLAP cube)는 대표적인 물리적 뷰로, 여러 차원의 집계를 격자(grid) 형태로 저장합니다. 예를 들어, 날짜와 상품별로 집계된 2차원 큐브를 만들 수 있습니다. <br>
복잡한 경우에는 여러 차원의 하이퍼큐브로 집계할 수 있습니다. 데이터 큐브는 빠른 쿼리를 지원하지만, 원시 데이터 쿼리의 유연성은 떨어집니다. 데이터 웨어하우스에서는 가능한 한 많은 원시 데이터를 유지하고, 특정 쿼리 성능 향상을 위해 선택적으로 물리적 집계를 사용합니다.

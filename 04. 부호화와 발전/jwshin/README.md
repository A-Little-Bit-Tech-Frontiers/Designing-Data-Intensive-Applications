# 4장. 부호화와 발전

-	애플리케이션은 시간이 지나며 기능, 데이터 사용 방식, 비즈니스 요구가 변한다.
-	변화에 흔들리지 않게 하려면 데이터를 어떻게 부호화(encoding)해서 저장/전달할지, 그리고 **스키마가 어떻게 발전**할지에 대한 원칙이 필요하다.

## 바뀌는 코드, 바뀌는 데이터

### 1. 점진적 배포와 동시 운영

- 실제 운영은 롤링 업그레이드/단계적 배포가 일반적.
  -	일부 인스턴스만 새 버전으로 교체 → 문제가 없으면 점차 확대.
-	그 결과 이전 버전 코드와 새 코드가 일정 기간 동시에 요청을 처리한다.
-	데이터 타입·스키마가 바뀌면 옛 코드/새 코드가 같은 저장소를 함께 사용해야 하므로 호환성이 관건.

### 2. 호환성의 두 축

- 하위 호환성(backward compatibility)
  - 새 코드가 이전 버전이 기록한 데이터를 읽을 수 있음.
- 상위 호환성(forward compatibility)
  - 옛 코드가 새 버전이 기록한 데이터를 읽어도 문제가 없음. (알 수 없는 필드는 무시하는 식)
- 업그레이드 동안 시스템을 멈추지 않고 연속적으로 운영하려면 두 방향의 호환성을 어떻게 달성/검증할지 설계에 포함해야 한다.

## 데이터 부호화(Encoding) 형식

### 1. 범주

- 언어 내장/전용 직렬화: Java Serializable, Ruby Marshal, Python pickle, Kryo 등
-	텍스트 기반: JSON, XML, CSV (+ 필요시 바이너리 포함을 위한 Base64)
-	스키마 기반 바이너리: Thrift, Protocol Buffers(=Protobuf), Avro

### 2. 언어 전용 직렬화의 한계

- 특정 언어/런타임에 강하게 결합됨 → 이종 언어/플랫폼 간 교환에 부적합.
-	버전 간 호환성 설계가 빈약해 스키마 발전 관리가 어렵다.
-	보안 이슈(불신 데이터 역직렬화)도 큼.
- 장기 저장/서로 다른 시스템 간 교환에는 권장되지 않음.

### 3. 텍스트 기반(JSON, XML, CSV)

- 장점: 사람이 읽기 쉬움, 광범위한 도구/라이브러리 지원, 스키마 없이도 어느 정도 사용 가능.
-	주의:
  -	숫자 표현(정밀도, 범위), 이진 데이터 표현(Base64), 시간/타임존, 선행/후행 공백, 구분자 등.
  -	스키마가 취약하면 검증/진화 규칙을 별도 합의로 관리해야 한다.
-	실무 요령: 다양한 시스템이 만나는 지점은 LCM(공통분모) 형식으로 단순하게—JSON/XML/CSV가 빈도가 높음.

### 4. 이진 부호화로의 압축

-	같은 내용이라도 텍스트(JSON) → 바이너리 부호화로 바꾸면 크기가 크게 줄어듦 (예제: 간단한 사용자 레코드).
-	하지만 단순 압축이 아니라 스키마를 갖춘 바이너리 형식을 쓰면 호환 규칙까지 체계화할 수 있다.

<img width="831" height="213" alt="image" src="https://github.com/user-attachments/assets/ad5573a5-18ce-49f9-88b1-0b7f96f32975" />

<img width="620" height="576" alt="image" src="https://github.com/user-attachments/assets/825f0a36-1794-4752-82c8-3654a805146c" />

- 위 이미지를 보면, JSON부호화는 81바이트인 반면, 이진 부호화는 66바이트로 비교적 공간을 덜 차지한다.
- 이 같은 공간의 절약과 파싱 속도 향상이 가독성을 해칠 만큼의 가치가 있는지는 확실하지 않지만, 부호화 데이터가 클수록 이득이 된다.

## 스키마 기반 바이너리: Thrift/Protobuf vs Avro

### 1. 공통점

-	**스키마 언어**로 레코드 구조를 정의하고, 그에 맞춰 코드를 생성하거나 런타임 직렬화를 수행.
-	스키마 발전 규칙을 제공해서 알 수 없는 필드 무시, 기본값, 필드 추가/삭제 등 호환 시나리오를 다룬다.

<img width="357" height="160" alt="image" src="https://github.com/user-attachments/assets/9cc20ba9-cc1e-415f-96bd-59ad201f2285" />
<img width="328" height="158" alt="image" src="https://github.com/user-attachments/assets/49836274-2da1-48f1-b409-3765ea72fdb0" />

### 2. Thrift & Protocol Buffers

- 각 필드에 **필드 태그(field tag)** 가 붙는다.
  -	직렬화 시 **(필드 태그, 타입, 값)** 이 함께 기록되므로 필드 이름이 바뀌어도 필드 태그만 유지하면 호환 가능.
- 프로토콜(인코딩 방식) 선택:
  - BinaryProtocol: 고정 길이 위주, 단순
  - CompactProtocol: 가변 길이 정수(Varint) 등으로 더 작게 표현
- 호환 규칙(요지) - 스키마 발전(schema evloution)
  - 추가: 새 필드는 보통 optional로 추가(옛 리더는 무시, 새 리더는 해석).
  - 삭제/이름 변경: 필드 태그를 재사용 금지. 삭제 시 필드 태그는 ‘영구 예약’으로 남겨 충돌 방지.
  - **필수(required)** 는 신중히: 호환성 깨뜨리기 쉬움.
  - 열거/반복 필드(repeated) 추가/변경 시도 규칙에 맞춰야 함.
 
<img width="649" height="513" alt="image" src="https://github.com/user-attachments/assets/6570d5fc-fc8b-42a3-b793-5967f9901620" />
<img width="638" height="491" alt="image" src="https://github.com/user-attachments/assets/399ac724-4e71-444f-b892-37d3580a1c79" />
<img width="635" height="432" alt="image" src="https://github.com/user-attachments/assets/2ca7ff3e-8c5a-4b20-8981-bd9a89f0aa94" />

### 3. Avro

- 직렬화 데이터에 필드 태그를 기록하지 않음(더 compact).
  - 대신 읽을 때 **writer’s schema(작성 당시 스키마)** 와 **reader’s schema(읽는 쪽 스키마)** 를 동시에 사용해 스키마 해석/매핑을 수행.
- 장점
  - 레코드에 스키마를 함께 담은 컨테이너 파일(object container file) 또는 메타데이터 저장소를 통해 자기 기술(self-describing) 가능 → 하둡/Hadoop 생태계에서 광범위 사용.
  - 스키마-온-리드(schema-on-read) 방식에 특히 유리(읽을 때 스키마를 적용).
- 호환 규칙(요지)
  - 필드 추가: **기본값(default)** 을 주면 옛 데이터도 읽을 수 있음.
  - 필드 삭제/이름 변경: 매핑 규칙에 따라 해석(단, 태그가 없으므로 이름/순서 변경은 더 신중).
  - Union 타입으로 값 부재/여러 타입을 표현.
  - 코드 생성이 필수는 아님(동적 사용도 가능) — 하지만 정적 타입 언어에선 코드 생성이 편리.

<img width="833" height="708" alt="image" src="https://github.com/user-attachments/assets/a2167404-668d-4d29-83d9-cd206b6ac903" />
<img width="613" height="462" alt="image" src="https://github.com/user-attachments/assets/72e733f2-8370-4367-a560-c39f13f6d2d0" />

## 스키마 발전의 실무 규칙

### 1. 공통 원칙

- 알 수 없는 필드는 무시(상위 호환).
- 기본값을 활용해 새 필드를 읽을 수 있게(하위 호환).
- **필드 식별자(Thrift/Proto)** 는 절대 재사용 금지.
-	required 남발 금물 — 업그레이드 중 혼재 환경을 깨뜨린다.

### 2. Avro의 쓰기/읽기 스키마

-	쓰기 스키마(writer): 데이터가 기록될 때 적용된 버전.
-	읽기 스키마(reader): 현재 애플리케이션이 기대하는 버전.
-	스키마 해석 규칙으로 두 버전을 자동 변환(기본값 대입, 필드 무시, 타입 호환 등).

### 3. 언제 쓰기 스키마가 필요해지는가
	
- 서로 다른 레코드가 섞이는 큰 파일/스트림(다양한 시점의 레코드가 함께 존재)
-	다수 프로듀서가 동시에 쓰는 데이터베이스/로그
-	네트워크 경계(프로세스 간 전송)—클라이언트/서버의 버전 차
-	동적 생성 스키마(관찰된 데이터에서 스키마 유추)

## 데이터플로(전달 경로)와 호환성

### 1. 데이터베이스를 통한 데이터플로

- 데이터는 코드보다 오래 산다.(data outlives code) - 수년 전 형식의 레코드가 현재 서비스에서 여전히 읽혀야 함.
- 호환 전략
  - 읽기 경로에서의 호환성 확보(옛 레코드 해석).
  - 필요시 **재부호화(re-encode, rewrite)** 로 새 스키마로 재작성.
  -	아카이브/스냅샷 등 보관 저장소는 **자기 기술 형식(스키마 동봉)** 으로 저장하는 편이 좋다.
 
<img width="840" height="438" alt="image" src="https://github.com/user-attachments/assets/150966e1-c580-4764-9320-13c73371f6f5" />

### 2. 서비스를 통한 데이터플로: REST와 RPC

- 웹 서비스(HTTP 기반)가 일반적.
  - REST 스타일: 리소스·표준 HTTP 동작 활용, JSON 등 텍스트 부호화가 흔함.
  - SOAP/WSDL: XML 기반 규격/도구화—복잡성·결합도 이슈.
- RPC 모델의 함정(위치 투명성의 환상)
  - 네트워크 호출은 부분 실패/타임아웃/재시도/중복 등 로컬 호출과 근본적 성격이 다름.
  - 버전 불일치·배포 순서·시간차가 서비스 경계의 진화 난이도를 높인다.
- 최근 경향
  - REST/HTTP+JSON이 상용·내부 API의 공통분모로 널리 사용.
  - RPC 프레임워크들도 프라미스/스트리밍 등으로 진화 중(그러나 여전히 호환성·진화는 API 계약의 문제).

### 3. 메시지 전달 데이터플로(비동기)

- 메시지 브로커/큐를 사이에 둔 비동기 통신.
  - 장점: 송신·수신 분리(결합도↓), 버퍼링/완충, 재시도·중복 감내, 여러 소비자에게 전달, 오프라인 수신 가능.
- 처리 모델
  - 발행/구독(Pub/Sub), 큐 기반 소비, 적어도 한 번 전달 등.
- 도구/프레임워크 예시: RabbitMQ, ActiveMQ, Kafka 등
- 분산 액터 모델(Akka, Orleans, Erlang/OTP 등)
  - 메시지 전달·격리를 전제로 동시성/분산 상태 관리를 단순화.
  - 메시지가 바이트열로 부호화되어 노드 간 전달되므로 앞서의 부호화/스키마 발전 원칙이 그대로 적용된다.
 
## 4장 정리

- 4장은 “데이터를 바이트로 어떻게 부호화하고 시간이 지나며 변경(발전) 되는가”에 초점을 맞춘다.
- 텍스트(JSON·XML·CSV)와 바이너리(Thrift·Protocol Buffers·Avro) 인코딩을 비교하며, 사람이 읽기 쉬움 vs. 효율성의 트레이드오프와 언어 독립성의 중요성을 강조한다.
- 핵심은 호환성 있는 스키마 진화: 새 필드는 보통 optional/기본값으로 추가하고(Avro는 기본값 필수), 리더-스키마/라이터-스키마 매칭으로 상·하위 호환을 보장하되, 필요할 때만 과거 데이터를 재부호화/백필한다.
- 데이터만이 아니라 인터페이스도 진화하므로, REST/HTTP(+JSON)와 RPC(Thrift·gRPC 등)의 장단, 버전 관리, 점진 배포(롤링/스테이지드) 원칙을 소개하며 느슨한 결합을 권장한다.
- 마지막으로 프로세스 간 데이터 전달은 데이터플로 관점에서 다루고, 메시지 브로커/큐(카프카 등)와 액터 모델(아카·오를레앙·OTP) 같은 비동기 방식이 서비스 분리와 업그레이드 내성을 높이는 방법임을 정리한다.

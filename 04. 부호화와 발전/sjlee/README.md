데이터 타입이나 스키마가 변경될 때, 코드 변경이 일어나야 한다. 보통 애플리케이션은 아래와 같이 코드 변경을 반영한다.

- 한 번에 몇 개의 노드에 새 버전을 배포하고 테스트 후에 서서히 모든 노드에 반영하는 순회식 업그레이드(rolling upgrade)
- 클라이언트 측 애플리케이션은 사용자에 좌우됨. 어떤 사용자는 한동안 업데이트를 안할 수도 있다.

정리하면, 예전 버전과 신규 버전의 시스템이 공존할 수 있는 것이다. 때문에, 양방향 호환성을 유지해야 한다.

- 하위 호환성
    
    새로운 코드는 예전 코드가 기록한 데이터를 읽을 수 있어야 함.
    
- 상위 호환성
    
    예전 코드는 새로운 코드가 기록한 데이터를 읽을 수 있어야 함.
    

하위 호환성은 예전 데이터를 알기에 명시적으로 다룰 수 있는 반면에, 상위 호환성은 예전 버전의 코드가 새 버전의 코드에 의해 추가된 것을 무시할 수 있어야 하므로 약간 복잡하다.

- 데이터 부호화 형식
    - JSON
    - XML
    - 프로토콜 버퍼(Protocol Buffers)
    - 스리프트(Thrift)
    - 아브로(Avro)
- REST, RPC, 메시지 큐 등에서 다양한 데이터 부호화 형식이 데이터 저장과 통신에 어떻게 사용되는지

# 1. 데이터 부호화 형식

다양한 데이터 구조는 CPU에서 효율적으로 접근하고 조작할 수 있게 최적화된다. 

파일에 쓰거나 네트워크에 전송하기 위한 부호화 구조와 메모리에서 읽는 데이터 구조는 매우 다르다. 때문에, 두 표현 사이의 전환이 필요하다.

- 부호화(직렬화): 인메모리 표현 → byte arr(책에선 예시를 JSON으로 들고 있음)
- 복호화(역직렬화): byte arr → 인메모리 표현

## 1.1 언어별 형식

많은 프로그래밍 언어는 인메모리 객체를 바이트열로 직렬화(부호화)하는 기능을 제공한다.

예:

- 자바 → `java.io.Serializable`
- 루비 → `Marshal`
- 파이썬 → `pickle`
- 자바 전용 → `Kryo` (서드파티 라이브러리)

이러한 내장 직렬화 라이브러리는 코드 작성이 간단하고 메모리에 있는 객체를 그대로 저장·복원할 수 있어 편리하지만, 동시에 많은 문제를 가진다.

- 부호화는 특정 프로그래밍 언어에 종속되므로, 다른 언어에서 데이터를 읽거나 해석하기 어렵다. 데이터가 장기간 사용되거나 다양한 시스템과 호환되어야 할 때 큰 제약이 된다.
- 동일한 객체 유형을 복원하려면 원래의 클래스를 다시 인스턴스화해야 하는데, 이는 보안 취약점이 될 수 있다. 
공격자가 조작된 바이트열을 제공하면 애플리케이션은 악의적 클래스를 불러올 수 있어 위험하다.
- 데이터 버전 관리 문제도 있다. 내장 직렬화는 데이터 형식이 바뀌면 호환성 유지가 어렵고, 상·하위 호환성을 보장하기 힘들다.
- 효율성 측면에서도 구조체 크기와 CPU 사용량이 커져 비효율적일 수 있다. 예를 들어 자바의 기본 `Serializable`은 직렬화 속도가 느리고 크기도 커서 성능상 불리하다.

⇒ 이런 이유들 때문에 언어에 내장된 직렬화 방식을 일반적인 데이터 저장·통신 목적으로 사용하는 것은 권장되지 않는다.

## 1.2 JSON과 XML, 이진변형

JSON과 XML은 널리 알려진 표준화된 데이터 직렬화 형식이다.

- **XML**: 표현력이 강력하지만 너무 복잡하고 장황하여 파싱이 어렵다.
- **JSON**: 브라우저에서 기본 지원되며 단순해 인기가 높다.
- **CSV**: 강력하진 않지만 단순하고 언어 독립적이라는 장점이 있다.

텍스트 형식인 JSON, XML, CSV 모두 사람이 읽기 쉽지만, 몇 가지 문제가 있다.

1. **숫자(Number) 부호화 문제**
    - JSON, XML, CSV는 수치 범위를 정확히 표현하기 어렵다.
    - 예를 들어 자바스크립트처럼 64비트 부동소수점을 사용하는 언어는 큰 정수를 정확히 표현하지 못한다.
    - JSON은 큰 수를 표현할 때 문자열로 다루는 방식으로 회피하지만, 여전히 애플리케이션에서 정밀도 손실 문제가 발생할 수 있다.
2. **텍스트 중심 한계**
    - JSON과 XML은 유니코드 텍스트를 잘 지원하지만, 바이너리 데이터(이미지, 영상 등)를 직접 표현하기는 어렵다.
    - 보통 Base64로 인코딩해 표현하지만, 이는 데이터 크기를 약 33% 증가시키고 해석 시 추가 비용이 발생한다.
3. **스키마 지원 부족**
    - XML은 스키마 정의를 지원하고 JSON도 일부 도구가 있지만, 강제성이 없어 일관된 데이터 구조 보장이 어렵다.
    - 애플리케이션 입장에서는 필요한 부호화/복호화 로직을 직접 구현해야 하는 경우가 많다.
4. **CSV의 한계**
    - 스키마가 없어 열과 열의 의미를 직접 정의해야 하고, 새로운 필드를 추가하면 해석 코드도 수정해야 한다.
    - 따라서 단순한 데이터 교환에는 적합하지만, 구조적 제약이나 확장성에는 불리하다.

⇒ JSON, XML, CSV는 여전히 단순성과 범용성 덕분에 다양한 용도에서 인기를 유지할 것이다. 특히 **조직 간 데이터 교환 형식**으로는 매우 유용하다. 하지만 복잡한 구조나 정밀도가 필요한 상황에서는 다른 형식이 더 적합할 수 있다.

## 1.3 이진 부호화

조직 내부에서만 데이터를 쓸 경우, 최소공통분모(LCDE, lowest-common-denominator encoding) 방식으로 단순한 형식을 써도 무방하다. 

하지만 대규모 데이터 전송이나 저장에서는 부호화 형식 선택이 성능과 효율성에 영향을 미친다.

- **JSON / XML**
    
    JSON은 단순하고 널리 쓰이지만, 공간 효율이 낮다. 이 문제를 보완하기 위해 JSON 기반의 다양한 **이진 부호화 형식**들이 개발되었다.
    
    예: 메시지팩(MessagePack), BSON, BJOSN, UBJSON, BISON, Smile, WBXML, Fast Infoset 등.
    
    → 하지만 JSON/XML처럼 널리 채택되진 않았다.
    
- **스키마 부재 문제**
    
    이진 부호화 형식도 JSON/XML 모델을 그대로 쓰면서 스키마를 강제하지 않는 경우가 많다. 따라서 모든 필드 이름을 문자열로 포함해야 하며, 데이터 크기가 증가하는 한계가 있다.
    

⇒ 이진 부호화(MessagePack 등)는 J**SON보다 크기를 줄이고 처리 속도를 개선**할 수 있지만, 스키마를 강제하지 않아 필드 이름 문자열을 계속 포함해야 하는 한계가 있다. 따라서 근본적인 효율성 문제를 완전히 해결하지는 못한다.

<img width="522" height="463" alt="image" src="https://github.com/user-attachments/assets/29e9e567-3b19-40ba-b892-460e4f8b5950" />


위 메시지 팩을 JSON으로 표현하면 아래와 같음

```json
{
  "userName": "Martin",
  "favoriteNumber": 1337,
  "interests": ["daydreaming", "hacking"]
}
```

다시 바꿔 말하면, 이를 메시지팩으로 부호화하면 **66바이트 크기**의 이진 데이터가 된다.

- 텍스트 JSON(81바이트)보다 작지만, 크기 차이는 미미하다.
- 장점: 직렬화/역직렬화 속도가 빠르고 공간 절약이 가능.
- 단점: 스키마를 지정하지 않기 때문에 여전히 모든 필드명을 문자열로 포함해야 함.

## 1.4 스리프트와 프로토콜 버퍼

아파치 **스리프트(Thrift)** 와 **프로토콜 버퍼(Protocol Buffers, protobuf)** 는 모두 이진 부호화 라이브러리로, 데이터를 효율적으로 직렬화하기 위해 **스키마(Interface Definition Language, IDL)** 가 필요하다.

- **스리프트 예제 스키마**
    
    ```
    struct Person {
        1: required string userName,
        2: optional i64 favoriteNumber,
        3: optional list<string> interests
    }
    ```
    
- **프로토콜 버퍼 예제 스키마**
    
    ```protobuf
    message Person {
        required string user_name = 1;
        optional int64 favorite_number = 2;
        repeated string interests = 3;
    }
    ```
    

스리프트와 프로토콜 버퍼의 스키마 정의 방식은 거의 유사하며, 각각 코드 생성을 위한 도구를 제공해 다양한 언어에서 직렬화/역직렬화를 쉽게 지원한다.

### **1.4.1 스리프트의 이진 부호화 방식**

스리프트는 대표적으로 두 가지 이진 부호화 프로토콜을 제공한다.

1. **바이너리 프로토콜 (BinaryProtocol)**
    - 예제 데이터를 59바이트로 부호화.
    - 각 필드에는 타입 정보, 길이, 값이 포함된다.
    - `username`, `favoriteNumber`, `interests` 같은 **필드 이름은 저장되지 않고** 숫자 태그(tag)만 저장된다.
2. **컴팩트 프로토콜 (CompactProtocol)**
    - 동일한 데이터를 34바이트로 줄여 표현 가능.
    - 숫자를 효율적으로 표현하기 위해 **variable-length integer** 방식 사용.
    - 예: 1337 같은 값은 2바이트로만 저장.
    - 데이터 크기를 크게 줄일 수 있다는 장점이 있다.

### 1.4.2 프로토콜 버퍼의 부호화 방식

- 동일한 데이터를 **33바이트**로 부호화.
- 스리프트의 컴팩트 프로토콜과 매우 유사하게 작동하며, 필드 태그 + 타입 + 값만 저장한다.
- 필드 정의에서 `required`와 `optional`을 구분할 수 있는데, 이진 데이터 자체에는 포함되지 않는다.
- 다만 `required` 설정은 실행 시 필드 누락 여부를 검증할 수 있어 **버그 탐지**에 유용하다.

⇒ 정리

- **스리프트와 프로토콜 버퍼**는 JSON보다 훨씬 효율적(공간·속도)이며, 구조적으로 엄격한 스키마 기반 직렬화를 제공한다.
- 스리프트는 다양한 프로토콜(Binary, Compact 등)을 제공하고, 프로토콜 버퍼는 단일 포맷이지만 매우 효율적이다.
- 두 방식 모두 데이터 크기를 크게 줄여 네트워크 전송과 저장 비용을 절약할 수 있으며, 대규모 시스템에서 많이 활용된다.

## 1.5 아브로

- 아브로(Avro)는 아파치에서 개발한 **이진 부호화 형식**으로, 프로토콜 버퍼와 스리프트와 유사하지만 **태그 번호가 필요 없다**는 점이 다르다.
- 스키마 기반 직렬화를 제공하며, 두 가지 스키마 언어를 지원한다.
    1. **Avro IDL**: 사람이 읽고 작성하기 쉬움.
    2. **JSON 기반 스키마**: 기계가 읽기 쉬움.

스키마는 아래와 같다.

- Avro IDL:
    
    ```
    record Person {
        string userName;
        union { null, long } favoriteNumber = null;
        array<string> interests;
    }
    ```
    
- JSON 스키마:
    
    ```json
    {
      "type": "record",
      "name": "Person",
      "fields": [
        {"name": "userName", "type": "string"},
        {"name": "favoriteNumber", "type": ["null", "long"], "default": null},
        {"name": "interests", "type": {"type": "array", "items": "string"}}
      ]
    }
    ```
    

**부호화 특징**

- 아브로는 태그 번호 대신 **스키마 정의 순서**에 따라 데이터를 직렬화한다.
- 예제 레코드를 부호화하면 **32바이트**로, 다른 이진 형식 중 가장 짧다.
- 데이터는 단순히 값들의 연속으로 기록되며, 별도의 타입 정보는 포함되지 않는다.
    
    → 따라서 **데이터를 해석하려면 동일한 스키마**가 반드시 필요하다.
    

⇒ 아브로는 **간결하고 효율적**인 이진 부호화 방식으로, JSON보다 훨씬 공간 절약적이다. 하지만 스키마에 의존하기 때문에 **쓰기 스키마와 읽기 스키마가 불일치하면 정확한 복호화가 불가능**하다.

## 1.6 쓰기 스키마와 읽기 스키마

- **쓰기 스키마(Writer’s schema)**: 애플리케이션이 파일/데이터베이스/네트워크에 데이터를 저장하거나 전송할 때 사용되는 스키마.
- **읽기 스키마(Reader’s schema)**: 저장된 데이터를 불러오거나 수신할 때 애플리케이션이 기대하는 스키마.

아브로(Avro)의 핵심은 **쓰기 스키마와 읽기 스키마가 동일할 필요는 없고, 호환 가능하기만 하면 된다**는 것이다.

- 아브로 라이브러리는 **쓰기 스키마와 읽기 스키마를 비교하여 차이를 해소**한다.
- 필드 순서는 달라도 문제 없음 → 이름으로 필드를 매칭하기 때문.
- 읽기 스키마에 없는 필드는 무시되고, 쓰기 스키마에 없지만 읽기 스키마가 기대하는 필드는 기본값으로 채워진다.

예시

<img width="523" height="201" alt="image" src="https://github.com/user-attachments/assets/9039bb14-851c-4caa-9682-648785b6ae01" />


- 쓰기 스키마에는 `userName`, `favoriteNumber`, `interests`, `photoURL`이 있음.
- 읽기 스키마에는 `userID`, `favoriteNumber`, `userName`, `interests`.
    
    → `photoURL`은 무시되고, `userID`는 기본값으로 채워짐.
    

**아브로는 스키마의 상·하위 호환성을 다음과 같이 정의**한다.

- **상위 호환성**: 새 쓰기 스키마로 기록된 데이터를 예전 읽기 스키마로 읽을 수 있음.
- **하위 호환성**: 예전 쓰기 스키마로 기록된 데이터를 새로운 읽기 스키마로 읽을 수 있음.

**규칙 요약**

- **필드 추가/삭제**
    - 필드 추가 시: 새 스키마에는 있지만 이전 스키마에는 없는 필드는 기본값으로 채워짐 → 하위 호환성 유지.
    - 필드 삭제 시: 이전 데이터에만 있는 필드는 새로운 스키마로 읽을 수 없으므로 상위 호환성 깨짐.
- **null 처리**
    - 아브로는 null을 임의 기본값으로 허용하지 않음.
    - 대신 **유니온 타입(union type)** 사용 → 예: `union {null, long, string}`.
    - 이는 어떤 값이 들어올 수 있는지 명확히 하여 버그 방지에 도움.
- **optional/required 불필요**
    - 프로토콜 버퍼, 스리프트와 달리 `optional`, `required` 같은 표시자가 없음.
    - 대신 **유니온 타입 + 기본값**으로 대체.
- **필드 이름 변경**
    - 아브로는 필드 이름을 기준으로 매칭하기 때문에 이름을 바꾸면 호환성이 깨짐.
    - 따라서 이름 변경은 하위 호환성만 유지되고, 상위 호환성은 없음.
- **유니온 타입 변경**
    - 새로운 요소를 추가하면 하위 호환성은 유지되지만 상위 호환성은 깨짐.

⇒ 아브로의 장점은 **스키마 유연성**이다. 쓰기·읽기 스키마가 달라도 기본값, 무시 규칙, 이름 매칭을 통해 호환성을 보장한다. 하지만 필드 이름 변경이나 기본값이 없는 필드 삭제는 상위 호환성을 깨뜨릴 수 있다.

## 1.7 그러면 쓰기 스키마는 무엇인가?

읽을 때 특정 데이터가 어떤 **쓰기 스키마**로 부호화되었는지 알아야 하는데, 모든 레코드에 전체 스키마를 넣는 것은 비효율적이다. 그래서 아브로는 상황에 따라 다른 방식을 쓴다.

1. **많은 레코드가 있는 대용량 파일**
    - 수많은 레코드가 모두 동일한 스키마로 부호화된다면, 파일 시작 부분에 한 번만 쓰기 스키마를 포함하면 된다.
    - 아브로에서는 이를 **객체 컨테이너 파일(Object Container File)** 이라고 한다.
2. **서로 다른 스키마를 가진 레코드가 있는 데이터베이스**
    - 각 레코드가 다른 쓰기 스키마를 가질 수 있음.
    - 해결책: 각 레코드 시작 부분에 **버전 번호**를 포함시키고, 데이터베이스는 버전 목록을 유지한다.
    - 읽는 쪽은 버전 번호를 확인 후 해당 스키마를 가져와 복호화.
3. **네트워크 전송**
    - 두 프로세스가 네트워크 연결을 맺을 때, **합의된 스키마 버전**을 사용.
    - 이후 연결이 유지되는 동안은 스키마를 반복해서 보내지 않아도 됨.

즉, 쓰기 스키마는 상황별로 다른 전략을 통해 관리되며, 버전 정보를 활용하는 방식이 핵심이다.

## 1.8 동적 생성 스키마

아브로의 큰 장점은 **태그 번호가 필요 없는 구조**라서 동적으로 스키마를 생성하고 관리하기 쉽다는 점이다.

- **관계형 데이터베이스 예시**
    - 데이터베이스 테이블 내용을 아브로 스키마로 변환 → 각 컬럼은 아브로 필드로 매핑.
    - 테이블 구조가 변경되면(컬럼 추가/삭제), 새로운 아브로 스키마를 생성하고 그대로 적용 가능.
    - 데이터 파일을 쓰는 사람은 필드가 추가된 사실을 몰라도, 이름 기반 매칭 덕분에 이전 쓰기 스키마와 여전히 호환됨.
- **스리프트/프로토콜 버퍼와 비교**
    - 스리프트·프로토콜 버퍼는 필드 태그를 직접 관리해야 해서, 스키마가 변할 때마다 태그 충돌을 피하기 위해 신중히 관리해야 한다.
    - 아브로는 동적 스키마 생성이 자연스러워, 설계와 관리가 훨씬 간단하다.

**정리**

- **쓰기 스키마**: 파일, DB, 네트워크 상황에 따라 효율적으로 포함/버전 관리됨.
- **동적 생성 스키마**: 아브로는 태그 번호가 없어, 스키마가 바뀌더라도 이름 매칭을 통해 손쉽게 호환 가능.
    
    → 따라서 **아브로는 유연성과 동적 환경에서의 적합성**이 뛰어나다.
    

# 2. 데이터플로 모드

- 서로 다른 프로세스 간에 데이터를 주고받을 때(네트워크 전송, 파일 기록 등) 데이터를 **바이트열로 부호화**해야 한다.
- 이 과정에서 중요한 개념은 **호환성** (상위·하위)과 **발전성**이다.
    - **발전성**: 시스템 전체를 동시에 바꾸지 않고, 일부만 독립적으로 업그레이드할 수 있는 능력.
    - **호환성**: 데이터를 생성하는 쪽과 읽는 쪽 프로세스가 서로 다른 버전이라도 데이터를 문제없이 주고받을 수 있는 관계.

즉, 데이터플로란 **한 프로세스에서 다른 프로세스로 데이터를 전달하는 방식**을 의미하며, 이를 구현하는 방법은 매우 다양하다.

## 2.1 데이터베이스를 통한 데이터플로

<img width="451" height="267" alt="image" src="https://github.com/user-attachments/assets/5e20e520-13d8-4cf4-af20-169010b2e6fb" />


- 데이터를 데이터베이스에 기록하는 프로세스는 데이터를 **부호화**해서 저장하고, 이를 읽는 프로세스는 데이터를 **복호화**한다.
- 같은 데이터베이스를 사용하는 경우, 쓰기와 읽기를 담당하는 프로세스는 서로 다른 시점에 실행될 수 있으며, 심지어 서로 다른 버전일 수도 있다.
- 따라서 데이터베이스는 마치 “미래의 자신에게 메시지를 남기는 것”과 같으며, 이 때문에 **하위 호환성**이 필수적이다.
그렇지 않으면 이전에 기록한 내용을 미래의 자신이 복호화할 수 없다.

여러 프로세스가 동시에 데이터베이스에 접근하는 환경에서는 일부는 새 코드, 일부는 이전 코드를 실행할 수 있다.

순차적 업그레이드 과정에서 이런 상황이 발생하며, 따라서 상위 호환성도 필요하다. 
즉, 새 코드로 기록된 데이터를 예전 코드가 읽을 수 있어야 한다.

문제는 레코드 스키마에 새 필드를 추가하는 경우다. 새 코드가 이 필드에 값을 기록하면, 이전 코드는 알 수 없는 필드이므로 무시하거나 기본값으로 처리해야 한다. 
반대로 예전 코드가 기록한 데이터에는 새 필드 값이 없으므로, 새 코드는 기본값으로 채워야 한다.

일부 부호화 형식은 알 수 없는 필드를 보존하지 못한다. 
예를 들어, 애플리케이션이 데이터를 객체로 디코딩 후 다시 인코딩할 때 원래 알 수 없는 필드가 유실될 수 있다. 이는 해결 가능한 문제지만 주의가 필요하다.

## 2.2 다양한 시점에 기록된 다양한 값

데이터베이스에는 과거에 기록된 값과 최근 값이 공존할 수 있다. 일부는 몇 밀리초 전에 저장된 값이고, 일부는 수년 전에 저장된 값일 수도 있다. 애플리케이션은 새로운 버전이 배포되면 이전 버전을 완전히 대체할 수 있지만, 데이터베이스의 내용은 과거 값이 그대로 남아 있다. 이런 상황을 흔히 **데이터가 코드보다 오래 산다(data outlives code)** 라고 표현한다.

데이터를 새로운 스키마로 다시 기록(마이그레이션)할 수는 있지만, 대규모 데이터셋에 대해 이 작업을 수행하는 것은 값비싸고 부담이 크기 때문에 대부분의 데이터베이스는 피한다.
대신 기존 데이터를 다시 쓰지 않고, 새로운 스키마에 추가된 필드에 대해서는 기본값을 설정하는 방식을 사용한다. (`secondaryId`처럼!)
예컨대 레코드를 읽을 때 저장된 데이터에 누락된 필드는 기본값으로 채운다.

따라서 스키마 발전은 저장소 안에 서로 다른 버전의 스키마로 부호화된 레코드가 함께 존재하게 만든다. 하지만 전체 데이터베이스 관점에서는 단일 스키마로 부호화된 것처럼 보이게 된다.

## 2.3 서비스를 통한 데이터플로: REST와 RPC

- **기본 구조**: 네트워크 통신은 보통 **클라이언트–서버 모델**로 동작한다.
    - 서버는 API를 제공(서비스),
    - 클라이언트는 API를 호출해 데이터 요청 및 처리.
- **웹 환경**:
    - 브라우저는 서버에 요청을 보내고, HTML·CSS·JS·이미지 등을 응답받음.
    - API는 HTTP, URL, SSL/TLS 같은 표준 프로토콜을 사용 → 상호운용성 높음.
    - 모바일 앱·데스크톱 앱도 클라이언트가 될 수 있으며, 주고받는 데이터는 보통 **JSON** 등으로 부호화됨.
- **서비스 간 통신**:
    - 서버가 다른 서비스의 클라이언트가 되기도 함.
    - 이러한 접근방식은 전통적으로 **SOA(서비스 지향 설계)라 불렸고,** 최근에는 이를  발전시켜 **마이크로서비스 아키텍처**로 불림.
- **데이터베이스와 비교**:
    - 데이터베이스는 자유로운 질의 가능.
    - 서비스는 비즈니스 로직 기반으로 제한된 API만 제공.
- **마이크로서비스 장점**:
    - 각 서비스는 독립적으로 배포·업데이트 가능.
    - 팀 단위로 자율적 운영 가능.
    - 단, 서버와 클라이언트가 항상 동시에 업그레이드되는 건 아니므로, **API 버전 간 호환성**이 중요.

## 2.4 웹 서비스

서비스와 통신하기 위한 기본 프로토콜로 HTTP를 사용할 때 이를 웹 서비스라 한다. 이는 웹뿐 아니라 다양한 상황에서도 쓰일 수 있다.

**예시:**

1. 사용자가 디바이스에서 실행하는 애플리케이션(웹 앱 등)이 HTTP로 서버에 요청을 보냄.
2. 서비스 지향/마이크로서비스 아키텍처의 일부로, 같은 조직의 다른 서비스가 HTTP API를 호출.
3. 인터넷을 통해 다른 조직의 서비스(API)를 호출. 예: 온라인 서비스 로그인 시 OAuth.

웹 서비스에는 크게 **REST**와 **SOAP** 방식이 있다.

- **REST**:
    - HTTP 원칙을 따르는 설계 철학.
    - 간단한 데이터 타입, URL과 리소스 활용, 캐시/인증/콘텐츠 전송 등에 HTTP 기능을 그대로 이용.
    - 최근에는 RESTful API 설계가 주류.
- **SOAP**:
    - 네트워크 API 요청을 위한 XML 기반 프로토콜.
    - HTTP 위에서 동작하긴 하지만 HTTP 기능을 적극 활용하지 않고, 자체 표준(WS-*)을 통해 복잡하고 다양한 기능을 지원.
    - SOAP API는 **WSDL(Web Services Description Language)** 로 정의됨.
    - 코드 생성을 자동화할 수 있지만, 복잡성과 상호운용성 문제로 점점 덜 쓰이고 있음.

결과적으로, 많은 대기업 시스템에서는 여전히 SOAP을 쓰기도 하지만, 일반적으로는 간단하고 유연한 RESTful API가 선호된다.

## 2.5 원격 프로시저 호출(RPC) 문제

웹 서비스에서 API 요청을 처리하기 위한 방법 중 하나가 **원격 프로시저 호출(RPC, Remote Procedure Call)** 이다. RPC는 1970년대부터 사용된 아이디어로, 네트워크 상의 서비스 요청을 마치 로컬 함수 호출처럼 보이게 하는 **위치 투명성(location transparency)** 개념을 기반으로 한다.

RPC는 처음에는 편리해 보이지만 실제로는 여러 문제를 가진다:

- **네트워크와 로컬 함수 호출의 차이**
    - 로컬 호출은 항상 결과를 반환하지만, 네트워크 요청은 실패하거나 응답이 지연될 수 있다.
    - 타임아웃, 무한 루프, 예외 등으로 네트워크 요청은 불확실성이 크다.
- **성능과 지연 시간**
    - 로컬 호출은 보통 마이크로초~~밀리초 단위지만, 네트워크 호출은 수 밀리초~~수 초까지 걸릴 수 있다.
    - 원격 서버의 상태에 따라 속도가 크게 달라질 수 있음.
- **중복 실행 문제**
    - 실패한 요청을 재시도하면 같은 작업이 여러 번 실행될 수 있다.
    - 이를 방지하려면 **멱등성(idempotence)** 같은 개념이 필요하다.
- **데이터 변환 문제**
    - 클라이언트와 서버가 다른 언어로 작성되면, 데이터 타입 변환 과정에서 불일치 발생 가능.
    - 예: 자바스크립트의 큰 정수 처리 문제(2⁵³ 이상 정수).

이러한 이유로 RPC는 복잡한 구조와 낮은 호환성 문제를 안고 있으며, REST 같은 방식과 달리 네트워크의 불안정성을 감추려 한다는 한계가 있다.

👉 결론: RPC는 로컬 호출처럼 보이게 하는 착시를 제공하지만, 네트워크의 본질적 문제(지연, 실패, 타입 불일치)를 숨길 수 없기 때문에 실무에서는 주의 깊게 다뤄야 한다.

## 2.6 RPC의 현재 방향

RPC는 여러 문제에도 불구하고 여전히 사용된다. 스리프트, 아브로도 RPC 지원 기능을 갖추고 있으며, gRPC는 프로토콜 버퍼를 기반으로 한 RPC 구현이다. 피네글(Finagle)은 스리프트를 사용하고 Rest.li는 HTTP 위에 JSON을 사용한다.

최근 RPC 프레임워크는 원격 요청이 로컬 함수 호출과 다르다는 점을 더 명확히 하고 있다.

- **Rest.li**: 실패할지도 모를 비동기 작업을 단순화하기 위해 퓨처(future)나 프라미스(promise) 사용.
- **푸치(Pucci)**: 병렬로 여러 서비스에 요청을 보내는 상황을 간소화하고 요청 결과를 취합.
- **gRPC**: 단일 요청/응답뿐 아니라 시간에 따른 스트리밍 요청·응답 지원.

또한 일부 프레임워크는 **서비스 찾기(service discovery)** 기능을 제공해 클라이언트가 특정 서비스를 찾을 수 있도록 돕는다.

REST와 비교하면, RPC는 더 세밀한 제어와 강력한 기능을 제공하지만, RESTful API는 훨씬 단순하고 광범위하게 사용된다. REST는 별도 소프트웨어 설치 없이도 브라우저나 커맨드라인 도구로 쉽게 요청을 보낼 수 있고, 주요 언어·플랫폼에서 광범위하게 지원되는 도구 생태계가 있다.

결론적으로 REST는 **공개 API**의 주류 방식으로 자리잡았고, RPC 프레임워크는 보통 데이터센터 내부나 특정 조직 소유의 서비스 간 요청에 주로 사용된다.

## 2.7 데이터 부호화와 RPC의 발전

서비스를 통한 데이터플로는 데이터베이스 기반 방식보다 발전성을 단순화할 수 있다. 서버와 클라이언트를 독립적으로 변경·배포할 수 있다고 가정하면, 요청은 하위 호환성과 응답은 상위 호환성이 필요하다.

- **RPC 스키마**:
    - 스리프트, gRPC(프로토콜 버퍼), 아브로 RPC 등은 각 부호화 형식의 호환성 규칙을 따른다.
    - SOAP은 XML 스키마 기반으로 요청과 응답을 정의한다. 발전은 가능하지만 제약이 많다.
    - RESTful API는 JSON을 일반적으로 사용하며, URI 부호화나 폼 부호화를 통한 매개변수 전달 방식을 활용한다. 새로운 필드 추가 시도 대부분 호환성을 유지한다.

RPC가 조직 간 통신에 쓰이면 서비스 호환성 유지가 더욱 어렵다. 서비스 제공자는 클라이언트를 강제로 업그레이드할 수 없기 때문에, API 버전은 오랜 기간 유지해야 하며, 보통 여러 버전의 API를 함께 운영한다.

**API 버전 관리 방식**은 다양하다.

- RESTful API에서는 URL 경로나 HTTP 헤더(Accept)에 버전 번호를 명시하는 방법이 흔하다.
- 특정 클라이언트 전용 API를 제공하거나, API 키와 함께 버전 정보를 관리하기도 한다.
- 일부 서비스는 별도 관리 인터페이스를 두어 클라이언트가 원하는 버전을 선택하게 한다.

👉 결론적으로, 데이터 부호화와 RPC 발전은 **서비스 독립적 배포**와 **API 버전 관리**를 가능하게 하면서도, 장기적인 호환성을 유지하기 위해 신중한 설계가 필요하다.

## 2.8 메시지 전달 데이터플로

REST와 RPC는 요청을 보내고 빠른 응답을 기대하는 방식이며, 데이터베이스는 데이터를 기록하고 나중에 읽는 방식이다. 이에 비해 **비동기 메시지 전달 시스템(asynchronous message-passing system)** 은 요청을 즉시 다른 프로세스로 전달하되, 결과를 기다리지 않고 메시지를 임시로 저장하는 **메시지 브로커(message broker)** 또는 **메시지 큐(message queue)**, **메시지 지향 미들웨어(message-oriented middleware)** 를 통해 전달한다.

메시지 브로커 방식의 장점:

- 수신자가 일시적으로 사용 불가능하거나 과부하 상태여도, 브로커가 메시지를 보관해 안정성을 높임.
- 메시지를 다시 전달할 수 있어 유실 방지 가능.
- 송신자는 수신자의 주소나 포트 번호를 몰라도 됨 → 클라우드 배포 환경에서 특히 유리.
- 하나의 메시지를 여러 수신자에게 전달 가능.
- 송신자와 수신자는 느슨하게 결합됨. 송신자는 메시지를 게시(publish)만 하면 되고, 누가 소비(consume)하는지는 상관하지 않아도 됨.

RPC와 달리 메시지 전달은 일반적으로 **단방향** 통신이다. 즉, 송신 프로세스는 메시지를 보낸 뒤 응답을 기다리지 않고, 메시지가 전달될 때까지 비동기로 처리된다.

## 2.9 분산 액터 프레임워크

**액터 모델(actor model)** 은 **단일 프로세스 안에서 동시성을 다루는 프로그래밍 모델**이다. 전통적인 스레드 기반 모델과 달리, 액터는 상태를 공유하지 않고 메시지 송수신으로만 통신한다. **각 액터는 독립적으로 실행되며 메시지는 유실될 수 있다는 가정하에 동작**한다. 따라서 교착 상태나 동기화 문제를 피할 수 있고, 동시성 처리가 단순해진다.

**분산 액터 프레임워크**에서는 이 모델이 여러 노드 간 애플리케이션 확장에 활용된다. 송신자와 수신자가 같은 노드에 있든 다른 노드에 있든 동일한 메시지 전달 구조를 사용하며, 다른 노드 간 통신은 메시지를 바이트열로 부호화해 네트워크를 통해 전달하고 복호화한다.

액터 모델은 RPC보다 위치 투명성(location transparency)에 더 충실하다. 네트워크 통신은 로컬 통신과 본질적으로 다르지만, 액터 모델은 메시지 유실 가능성을 이미 전제하므로 현실적인 접근이 가능하다.

---

분산 액터 프레임워크는 기본적으로 메시지 브로커와 액터 모델을 통합한다. 다만 애플리케이션 업그레이드 시 새 버전 메시지가 이전 버전과 함께 동작할 수 있으므로 **상위·하위 호환성**에 주의해야 한다.

대표적인 프레임워크는 다음과 같다:

- **아카(Akka)**: 자바/스칼라 기반, 내부 전달방식을 사용. 높은 상위/하위 호환성은 보장하지 않으나, 다양한 배포 환경에서 쉽게 업그레이드 가능.
- **오를리앙(Orleans)**: .NET 기반, 액터를 "가상 액터"로 관리. 메시지 유실을 최소화하고 업그레이드 시 클러스터링 기능을 제공.
- **얼랭(Erlang)**: 전통적 액터 모델 구현. 전 세계적으로 안정성 높은 시스템에 사용되며, 레코드 스키마 변경도 외부 도구 없이 지원. JSON과 같은 텍스트 형식 대신 자체 직렬화 포맷을 사용해 효율적.

**정리**

- 액터 모델
    - 각 **액터 자체가 메시지 큐를 내장**하고 있는 개체라고 보면 됨.
    - 외부에서 메시지를 보내면 액터의 큐에 쌓이고, 액터는 이걸 **하나씩 순차적으로 처리**.
    - 액터는 독립된 상태(state)를 가지고 있고, 메시지를 처리하는 동안만 자신의 상태를 바꿈.
- 요약하면, 분산 액터 프레임워크는 **메시지 기반 통신 + 독립적 실행**이라는 액터 모델의 특성을 분산 환경으로 확장해, 안정적이고 유연한 시스템을 만들 수 있게 한다.

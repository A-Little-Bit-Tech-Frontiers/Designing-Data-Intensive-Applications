# 부호화와 발전

이 장에서는 애플리케이션의 변화가 불가피하다는 점과 시스템을 설계할 때 적응성을 염두에 두는 것이 중요함을 강조합니다. <br>
애플리케이션 기능의 수정은 종종 데이터 저장 방식의 조정을 필요로 하며, 이 장에서는 코드 변경을 처리하는 전략과 점진적 배포 및 사용자별 업데이트가 이루어지는 대규모 애플리케이션에서의 어려움을 다룹니다. <br>
주요 개념으로는 **하위 호환성(새로운 코드가 이전 코드의 데이터를 읽는 것)** 과 **상위 호환성(이전 코드가 새로운 코드의 데이터를 읽는 것)** 이 소개됩니다. <br>
또한, 다양한 데이터 인코딩 포맷과 이들이 웹 서비스, REST, RPC, 메시지 전달 시스템에서 스키마 변경을 처리하는 역할을 탐구합니다.

## 데이터 부호화 형식

프로그램은 일반적으로 데이터를 최소 두 가지 다른 형태로 다룹니다:

1. **메모리 내 데이터 표현**:
    - 데이터는 객체, 구조체, 리스트, 배열, 해시 테이블, 트리 등 다양한 형태로 존재합니다.
    - CPU가 효율적으로 접근하고 조작할 수 있도록 최적화되어 있으며, 종종 포인터를 활용합니다.

2. **외부 데이터 표현**:
    - 데이터를 파일에 저장하거나 네트워크로 전송하려면, 데이터를 독립적인 바이트 열로 인코딩해야 합니다. (예시: JSON 문서로 인코딩.)
    - 외부 프로세스에서는 포인터를 사용할 수 없으므로, 바이트 열의 표현 방식은 메모리 내 데이터 구조와 크게 다릅니다.

따라서 두 표현 방식 간 변환이 필요합니다. <br>
메모리 내 표현을 바이트 시퀀스로 변환하는 과정을 **인코딩**(직렬화, 마샬링)이라 하고, 바이트 시퀀스를 다시 메모리 내 표현으로 변환하는 과정을 **디코딩**(파싱, 역직렬화, 언마샬링)이라 합니다.

### 언어별 포맷

많은 프로그래밍 언어에서 메모리 내 객체를 바이트 시퀀스로 인코딩하는 내장 기능을 제공합니다.

예시:
- Java: `java.io.Serializable`
- Ruby: `Marshal`
- Python: `pickle`
- Java용 서드파티 라이브러리로 Kryo 등이 있습니다.

언어별 인코딩의 문제점:
1. **언어 종속성**: 인코딩이 특정 언어에 종속되어 있어, 다른 언어에서 데이터를 읽기 어렵고 상호 운용성이 떨어집니다.
2. **보안 문제**: 디코딩 과정에서 임의의 클래스를 인스턴스화해야 하므로 보안 위험이 있습니다. 공격자가 디코딩을 악용해 임의의 코드를 실행할 수 있습니다.
3. **버전 관리 미흡**: 대부분의 라이브러리에서 데이터 버전 관리가 제대로 지원되지 않아, 상위/하위 호환성 문제가 발생할 수 있습니다.
4. **효율성 문제**: 인코딩 라이브러리가 CPU 시간이나 인코딩 크기 면에서 비효율적일 수 있습니다. 예를 들어, Java의 내장 직렬화는 성능 저하와 인코딩 크기 증가로 비판받습니다.

### JSON, XML, 바이너리 변형

표준화된 인코딩 방식으로 JSON과 XML이 널리 사용됩니다. <br>
하지만 XML은 장황하고 복잡하며, JSON은 브라우저 지원과 단순함 덕분에 인기가 있지만 모두가 선호하지는 않습니다. <br>
CSV도 언어 독립 포맷이지만, JSON이나 XML보다 기능이 제한적입니다.

**바이너리 인코딩:**
조직 내에서만 데이터를 사용할 경우, 더 compact하거나 빠른 포맷을 자유롭게 선택할 수 있습니다. <br>
JSON이 XML보다 덜 장황하지만, 둘 다 바이너리 포맷에 비해 공간을 많이 차지합니다. <br>
이에 따라 MessagePack, BSON, UBJSON 같은 JSON의 바이너리 변형과 WBXML, Fast Infoset 같은 XML의 바이너리 변형이 등장했습니다. <br>
그러나 이 바이너리 포맷들은 텍스트 버전만큼 널리 쓰이지는 않습니다. 데이터셋이 테라바이트 단위로 커질수록 포맷 선택이 중요해집니다.

일부 포맷은 정수와 부동소수점 구분, 바이너리 문자열 지원 등 데이터 타입을 확장하지만, 기본적으로 JSON/XML 데이터 모델을 유지하며 스키마를 요구하지 않습니다. 즉, 모든 필드 이름이 인코딩된 데이터에 포함됩니다. <br>
예를 들어, 아래 JSON 문서는 사용자 정보를 담고 있습니다.

```json
{
    "userName": "Martin",
    "favoriteNumber": 1337,
    "interests": ["daydreaming", "hacking"]
}
```

MessagePack(바이너리 JSON 인코딩)을 예로 들면, 인코딩된 바이트 시퀀스는 객체와 필드 수를 표시하며, 바이너리 인코딩은 66바이트로 텍스트 JSON(공백 제외 81바이트)보다 약간 작습니다. <br>
공간 절약과 파싱 속도 향상은 있지만, 사람에게 읽기 어렵다는 단점이 있습니다. 이후에는 같은 레코드를 32바이트로 인코딩하는 더 효율적인 방법을 다룹니다.

<img width="582" height="539" alt="Image" src="https://github.com/user-attachments/assets/8166fe91-465e-4401-b669-749572284c83" />

### Thrift와 Protocol Buffers

**Apache Thrift**와 **Protocol Buffers(protobuf)** 는 각각 Facebook과 Google에서 개발되어 2007~2008년에 오픈소스화된 바이너리 인코딩 라이브러리입니다. <br>
두 포맷 모두 데이터 인코딩을 위해 **스키마**가 필요합니다. Thrift는 Thrift IDL, Protocol Buffers는 유사한 스키마 정의 언어를 사용합니다. 두 포맷 모두 스키마 기반으로 다양한 언어의 클래스를 생성하는 코드 생성 도구를 제공합니다.

Thrift 예시:
```thrift
struct Person {
  1: required string userName,
  2: optional i64 favoriteNumber,
  3: optional list<string> interests
}
```

Protocol Buffers 예시:
```protobuf
message Person {
  required string user_name = 1;
  optional int64 favorite_number = 2;
  repeated string interests = 3;
}
```

Thrift는 BinaryProtocol과 CompactProtocol 두 가지 바이너리 인코딩을 지원하며, CompactProtocol은 비트 패킹과 가변 길이 정수로 더 작은 크기를 만듭니다. <br>
예시로 BinaryProtocol은 59바이트, CompactProtocol은 34바이트를 차지합니다.

Protocol Buffers는 한 가지 바이너리 인코딩 포맷을 사용하며, 같은 데이터를 33바이트로 인코딩합니다. <br>
스키마는 필수/옵션 필드를 구분하지만, 인코딩 방식에는 영향을 주지 않고 런타임 체크에만 사용됩니다.

<img width="603" height="472" alt="Image" src="https://github.com/user-attachments/assets/4d2ad096-ecc9-4f20-b86b-2dacb7ac297d" /> <br>
<img width="606" height="478" alt="Image" src="https://github.com/user-attachments/assets/60b56bf0-99e3-4f64-8bb3-c7e780a3c8e4" />

**필드 태그와 스키마 발전:**
Thrift와 Protocol Buffers에서 인코딩된 레코드는 태그 번호와 데이터 타입으로 식별되는 필드가 연결된 형태입니다. 필드 이름 변경은 가능하지만 태그 번호 변경은 기존 데이터와 호환성을 깨뜨리므로 불가합니다.

스키마 발전 시, 새로운 태그 번호로 필드를 추가하여 상위 호환성을 확보할 수 있고, 기존 배포 이후에는 옵션 또는 기본값 필드만 추가해야 하위 호환성이 유지됩니다. 필드 제거도 옵션 필드만 가능하며, 기존 태그 번호 재사용은 금지됩니다.

**데이터 타입과 스키마 발전:**
필드의 데이터 타입 변경은 가능하나, 정밀도 손실이나 잘림 위험이 있습니다. 예를 들어, 32비트 정수를 64비트로 변경하면, 이전 코드가 새로운 데이터를 읽을 때 잘림이 발생할 수 있습니다.

Protocol Buffers는 리스트 대신 반복(repeated) 마커를 사용하며, 단일 필드를 반복 필드로 변경하는 것이 가능합니다. 새로운 코드는 0~1개 요소의 리스트로 인식하고, 이전 코드는 리스트의 마지막 요소만 읽습니다.

Thrift는 전용 리스트 타입을 사용하며, 단일→다중 값 발전는 불가하지만 중첩 리스트는 지원합니다.

### Avro

Apache Avro는 2009년 Hadoop의 서브프로젝트로 등장한 독특한 바이너리 인코딩 포맷입니다. Thrift가 Hadoop에 적합하지 않다는 인식에서 시작되었습니다. <br>
Avro는 스키마로 데이터 구조를 정의하며, 사람이 편집하기 쉬운 Avro IDL과 기계가 읽기 쉬운 JSON 기반 스키마 언어를 모두 제공합니다.

Avro IDL 예시:
```avro
record Person {
  string userName;
  union { null, long } favoriteNumber = null;
  array<string> interests;
}
```

동일한 JSON 스키마:
```json
{
  "type": "record",
  "name": "Person",
  "fields": [
    {"name": "userName", "type": "string"},
    {"name": "favoriteNumber", "type": ["null", "long"], "default": null},
    {"name": "interests", "type": {"type": "array", "items": "string"}}
  ]
}
```

Thrift와 Protocol Buffers와 달리, Avro는 스키마에 태그 번호를 사용하지 않습니다. 예시 레코드를 인코딩하면 32바이트로 가장 compact한 결과를 얻습니다. <br>
바이트 시퀀스에는 필드나 데이터 타입 식별자가 없고, 값만 연결되어 있습니다. 따라서 스키마를 알아야만 올바르게 디코딩할 수 있습니다. 스키마가 다르면 데이터 해석이 잘못될 수 있습니다. <br>
Avro는 시간이 지나면서 스키마 변경을 지원합니다.

<img width="621" height="407" alt="Image" src="https://github.com/user-attachments/assets/a9484480-3503-4268-ad94-0e8b65876f4a" />

**Writer 스키마와 Reader 스키마:**
Avro에서 데이터를 인코딩할 때 애플리케이션은 자신이 아는 버전의 writer 스키마를 사용하며, 파일/DB에 저장하거나 네트워크로 전송합니다. 디코딩 시에는 reader 스키마를 사용하며, 이는 애플리케이션 코드가 기대하는 스키마입니다.

Writer와 Reader 스키마는 반드시 동일할 필요는 없고, **호환성**만 있으면 됩니다. Avro 라이브러리는 두 스키마를 비교해 차이를 해소하고 데이터를 변환합니다.

예를 들어, 스키마의 필드 순서가 달라도 필드 이름으로 매칭하므로 문제없습니다. Reader에 없는 필드는 무시되고, Reader가 기대하지만 Writer에 없는 필드는 Reader의 기본값으로 채웁니다.

<img width="584" height="265" alt="Image" src="https://github.com/user-attachments/assets/28d6eb0e-58d6-4d63-bb2f-c7b22fa98cb7" />

**스키마 발전 규칙:**
Avro에서 상위 호환성은 새 버전이 Writer, 이전 버전이 Reader일 때 성립합니다. 하위 호환성은 새 버전이 Reader, 이전 버전이 Writer일 때 성립합니다.

호환성을 위해서는 기본값이 있는 필드만 추가/제거할 수 있습니다. 기본값 없이 필드를 추가하면 하위 호환성이 깨지고, 기본값 없이 필드를 제거하면 상위 호환성이 깨집니다. Avro는 옵션/필수 마커 대신 union 타입과 기본값으로 null 가능성을 처리합니다.

필드 타입 변경은 Avro가 변환할 수 있을 때만 가능하며, 필드명 변경은 하위 호환성만 보장됩니다. union 타입에 분기를 추가하는 것은 하위 호환성이지만 상위 호환성은 아닙니다.

**Writer 스키마란?**
Avro에서 특정 데이터의 writer 스키마 결정은 사용 사례에 따라 다릅니다.

1. 대용량 파일(수백만 레코드):
    - 모든 레코드가 동일한 스키마로 인코딩될 때, 파일 앞부분에 스키마를 한 번 포함합니다.
    - Avro는 object container 파일 등 파일 포맷을 정의합니다.

2. DB에 개별적으로 저장되는 레코드:
    - 각 레코드가 서로 다른 시점에 다른 스키마로 저장된다면, 레코드 앞부분에 버전 번호를 포함합니다.
    - DB는 스키마 버전 목록을 관리하며, Reader가 해당 버전의 스키마를 찾아 디코딩합니다. Espresso가 대표적입니다.

3. 네트워크로 레코드 전송:
    - 양방향 네트워크 연결 시, 연결 설정 단계에서 스키마 버전을 협상합니다.
    - 협상된 스키마는 연결이 유지되는 동안 사용됩니다. Avro RPC 프로토콜이 이를 활용합니다.

모든 경우, 스키마 버전 DB는 문서 역할과 호환성 체크에 도움을 줍니다. 버전 번호는 단순 증가 정수 또는 스키마의 해시값이 될 수 있습니다.

**동적으로 생성되는 스키마:**
Avro의 태그 번호 없는 스키마 설계는 Thrift, Protocol Buffers보다 동적 스키마 처리에 유리합니다.

1. 관계형 DB 예시:
    - 관계형 DB를 바이너리 포맷으로 덤프할 때, DB 스키마에서 바로 Avro 스키마를 생성할 수 있습니다.
    - 각 테이블은 Avro 레코드 스키마가 되고, 각 컬럼은 해당 레코드의 필드가 됩니다(컬럼명 기준 매핑).

2. 스키마 변경:
    - DB 스키마가 변경되면(컬럼 추가/제거), 새 Avro 스키마를 쉽게 생성할 수 있습니다.
    - 데이터 내보내기 과정에서 매번 자동 변환이 이루어지므로, 별도 처리 없이 스키마 변경을 수용할 수 있습니다.

3. 동적 스키마 생성:
    - Avro 설계는 동적 스키마 생성 목표에 부합합니다. 예를 들어, DB 스키마 변경 시, 필드를 이름 기준으로 자동 식별합니다.
    - 태그 번호 관리가 필요 없으므로, 수동 관리나 오류 위험이 줄어듭니다.

4. Thrift/Protocol Buffers 비교:
    - 반면, Thrift/Protocol Buffers는 DB 스키마 변경 시 태그 번호 할당을 수동으로 관리해야 하며, 재사용 방지 등 관리가 번거롭고 오류 위험이 있습니다.

요약하면, Avro는 동적 스키마가 필요한 상황에서 Thrift/Protocol Buffers보다 편리하고 자동화된 스키마 변경 처리를 제공합니다.

**코드 생성과 동적 타입 언어:**
Thrift와 Protocol Buffers는 코드 생성에 의존하는데, 이는 정적 타입 언어에서는 유용하지만 동적 타입 언어에서는 덜 실용적입니다. Avro는 코드 생성이 선택적이며, 코드 생성 없이도 효과적으로 사용하도록 설계되었습니다.

이 점은 JavaScript, Ruby, Python 같은 동적 타입 언어에서 장점이 됩니다. Avro는 자체 기술 정보를 포함하므로, 생성된 코드 없이도 데이터를 직접 확인할 수 있습니다. 예를 들어, Apache Pig에서 Avro 파일을 다룰 때, 명시적 스키마 없이도 분석, 파생 데이터셋 생성, 파일 출력이 가능합니다. 이로 인해 Avro는 동적 데이터 처리에 특히 유용합니다.

### 스키마의 장점

요약하면, Protocol Buffers, Thrift, Avro 같은 바이너리 인코딩에서 스키마를 사용하는 것은 JSON, XML, CSV 같은 텍스트 포맷에 비해 여러 가지 이점을 제공합니다.

1. **단순성과 구현 용이성**: 바이너리 포맷의 스키마 언어는 XML Schema, JSON Schema보다 단순해 구현과 사용이 쉽고, 다양한 언어를 지원합니다.
2. **역사적 배경**: 이 인코딩 개념은 1984년 표준화된 ASN.1 같은 오래된 기술에서 비롯되었으나, 최신 바이너리 포맷이 이를 개선했습니다.
3. **컴팩트함**: 바이너리 인코딩은 필드명을 생략할 수 있어 "바이너리 JSON"보다 더 compact할 수 있습니다.
4. **문서화와 검증**: 스키마 자체가 유용한 문서 역할을 하며, 실제 데이터 구조와 동기화가 쉬워집니다. 상세한 검증 규칙도 지원해 데이터 무결성 보장이 강화됩니다.
5. **호환성 체크**: 스키마 DB를 유지하면, 배포 전 스키마 변경의 상/하위 호환성 체크가 가능합니다.
6. **코드 생성**: 정적 타입 언어 사용자는 스키마 기반 코드 생성으로 컴파일 타임 타입 체크의 이점을 누릴 수 있습니다.

결론적으로, 바이너리 인코딩에서 스키마 발전 개념을 도입하면, 스키마 없는 JSON DB의 유연성을 유지하면서 더 나은 데이터 보장과 개선된 도구 지원을 받을 수 있습니다.

## 데이터플로 모드

네트워크 전송이나 파일 저장처럼 메모리를 공유하지 않는 프로세스 간에 데이터를 주고받을 때 사용되는 다양한 인코딩 방식에 대해 살펴보았습니다. 시스템 진화를 위해서는 상위/하위 호환성이 중요하다는 점도 논의했습니다. <br>
이제 프로세스 간 데이터 흐름의 다양한 방식에 대해 알아보겠습니다.

- **데이터베이스를 통한 데이터 흐름**: 데이터가 데이터베이스를 통해 어떻게 이동하는지, 저장 시스템에서 인코딩의 역할, 그리고 데이터베이스 스키마 진화가 미치는 영향을 살펴봅니다.
- **서비스(REST와 RPC)를 통한 데이터 흐름**: 서비스 호출을 통해 프로세스 간 데이터가 어떻게 교환되는지, REST와 RPC(원격 프로시저 호출) 방식을 비교합니다.
- **메시지 전달 방식**: 프로세스 간 비동기 메시지 전달 방식과 분산 시스템에서의 중요성을 탐구합니다.

이러한 방식들은 데이터가 프로세스 간 이동하는 일반적인 시나리오이며, 각각 인코딩, 호환성, 시스템 설계에 대해 고려해야 할 점이 존재합니다.

### 데이터베이스를 통한 데이터 흐름

데이터베이스 작업에서는 쓰기 프로세스가 데이터를 인코딩하고, 읽기 프로세스가 이를 디코딩합니다. 하나의 프로세스가 데이터베이스에 접근한다면, 읽는 프로세스를 미래의 자기 자신으로 보는 것과 비슷합니다. <br>
**하위 호환성**은 이전에 저장된 데이터를 올바르게 디코딩하는 데 필수적입니다. 여러 프로세스가 동시에 데이터베이스에 접근하는 경우, 각기 다른 코드 버전이 존재할 수 있으므로 **상위 호환성**도 중요합니다. <br>

레코드 스키마에 새 필드를 추가하는 것은 도전 과제입니다. 최신 코드가 새 필드에 값을 기록하고, 이전 버전이 이를 읽고 수정해 다시 저장할 때 새 필드가 보존되길 원합니다. <br>
인코딩 포맷이 알려지지 않은 필드를 처리할 수 있어도, 디코딩 및 재인코딩 과정에서 데이터 손실을 막기 위해 애플리케이션 수준에서 주의가 필요합니다.

<img width="728" height="403" alt="Image" src="https://github.com/user-attachments/assets/fd7b3cfc-a53c-4f38-b4c6-dfd0bac4c533" />

**다양한 시점에 기록된 다양한 값:**

데이터베이스에서는 언제든 값이 수정될 수 있어, 수 밀리초에서 수년에 이르는 다양한 시점에 기록된 데이터가 혼재합니다. <br>
애플리케이션 코드는 빠르게 교체될 수 있지만, 데이터베이스의 데이터는 명시적으로 재작성하지 않는 한 오래 남아 있습니다. 이를 "데이터가 코드보다 오래 산다"라고 표현합니다. <br>
대규모 데이터셋의 경우 새 스키마로 데이터 마이그레이션이 가능하지만 비용이 많이 들기 때문에, 데이터베이스는 이를 가급적 피하려 합니다. <br>
대부분의 관계형 데이터베이스는 새 컬럼을 null 기본값으로 추가하는 등 간단한 스키마 변경을 지원하며, 기존 데이터는 재작성하지 않습니다. <br>
예를 들어, LinkedIn의 Espresso 문서 데이터베이스는 Avro를 활용해 스키마 진화 규칙의 이점을 누립니다. <br>
이 접근 방식 덕분에 데이터베이스 전체가 하나의 스키마로 인코딩된 것처럼 보이지만, 실제 저장소에는 다양한 과거 스키마 버전의 레코드가 존재할 수 있습니다.

**아카이브 저장 및 데이터 덤프:**

백업이나 데이터 웨어하우스 등 주기적으로 데이터베이스 스냅샷을 생성할 때, 데이터 덤프는 최신 스키마로 인코딩됩니다. <br>
원래의 다양한 스키마 버전과 관계없이 일관된 인코딩이 적용됩니다. 데이터 덤프의 불변성 때문에 Avro 오브젝트 컨테이너 파일 같은 포맷이 적합하며, 복사 과정에서 일관된 인코딩을 사용하는 것이 실용적입니다. <br>
분석 기능 강화를 위해서는 Parquet 같은 컬럼 지향 포맷도 고려할 수 있습니다.

### 서비스(REST와 RPC)를 통한 데이터 흐름

네트워크 통신 모델에서는 클라이언트가 서버와 API를 통해 상호작용합니다. 웹에서는 브라우저, 네이티브 앱, 자바스크립트 앱 등이 클라이언트 역할을 하며, HTTP 같은 표준을 통해 서버에 요청을 보냅니다. <br>
서비스는 데이터베이스와 유사하게 데이터 제출 및 조회를 가능하게 하지만, 더 제한적이고 애플리케이션 특화된 API를 제공합니다. <br>
서비스 지향 또는 마이크로서비스 아키텍처에서는 독립적인 배포와 진화가 중요하며, 다양한 서비스 버전이 공존할 수 있으므로 API 버전 간 호환 가능한 데이터 인코딩이 필수입니다.

**웹 서비스:**

웹 서비스는 HTTP를 기반으로 하며, 웹뿐 아니라 다양한 환경에서 사용됩니다. 예를 들어, 인터넷을 통한 클라이언트 앱, 동일 조직 내 데이터센터 서비스, 조직 간 데이터 교환 등이 있습니다. <br>
REST와 SOAP은 대표적인 웹 서비스 접근 방식입니다. REST는 HTTP 원칙에 기반한 설계 철학으로, URL로 리소스를 식별하고 HTTP 기능을 적극 활용해 단순함을 추구합니다. <br>
SOAP은 XML을 활용한 네트워크 API 프로토콜로, WS-*와 같은 표준을 포함한 복잡한 프레임워크입니다. SOAP은 대기업에서 여전히 쓰이지만, RESTful API가 단순함과 사용 편의성 덕분에 더 널리 퍼졌습니다. <br>
RESTful API는 코드 생성이 적고, OpenAPI(Swagger) 같은 포맷으로 API 설명과 문서화가 가능합니다. SOAP은 대기업에서 사용되지만, RESTful API가 현대에는 더 인기 있습니다.

**RPC(원격 프로시저 호출)의 문제점:**

EJB, RMI, DCOM, CORBA 등 RPC 기술은 근본적인 한계에 부딪혔습니다.

- 위치 투명성의 오류: 네트워크 서비스를 로컬 함수 호출처럼 보이게 하려 하지만, 네트워크와 로컬 호출의 본질적 차이를 간과합니다.
- 네트워크 요청의 불확실성: 요청/응답 손실, 네트워크 장애, 느린/불능 원격 머신 등 다양한 문제가 발생할 수 있어 대비와 재시도가 필요합니다.
- 요청 결과의 불확실성: 타임아웃 등으로 결과가 없을 수 있어, 성공/실패 여부를 별도로 처리해야 합니다.
- 재시도와 멱등성: 실패한 네트워크 요청을 멱등성 없이 재시도하면 동작이 여러 번 실행될 수 있습니다.
- 지연 시간의 다양성: 네트워크 요청 지연은 환경에 따라 수 밀리초~수 초로 다양하며, 로컬 호출과 다릅니다.
- 파라미터 인코딩 부담: 네트워크 요청은 바이트 시퀀스로 파라미터 인코딩이 필요해, 큰 객체 처리에 부담이 있습니다.
- 언어 간 데이터 타입 변환: RPC 프레임워크는 언어별 타입 차이로 데이터 변환에 어려움을 겪습니다.

이런 문제에도 불구하고, REST는 네트워크 프로토콜임을 명확히 드러내며, 로컬 함수 호출과 과도하게 비슷하게 만들려는 함정을 피합니다.

**RPC의 최신 동향:**

RPC는 서비스 통신 방식으로 여전히 인기가 있으며, 최신 프레임워크는 Protocol Buffers, Avro, JSON over HTTP 등 다양한 인코딩 포맷을 통합합니다.

- 명시적 원격 요청 처리: Finagle, Rest.li 등은 비동기 작업과 실패 처리를 위해 future를 활용, 로컬 함수와 원격 요청의 차이를 인식합니다.
- 고급 기능 지원: gRPC는 스트림 지원으로 다수의 요청/응답을 시간에 따라 양방향으로 주고받을 수 있습니다.
- 서비스 디스커버리: 일부 프레임워크는 서비스 위치를 동적으로 찾는 기능을 내장합니다.
- 성능 vs 유연성: 바이너리 인코딩을 사용하는 커스텀 RPC는 성능 면에서 우위가 있지만, RESTful API는 실험, 다양한 언어 지원, 풍부한 도구 측면에서 장점이 있습니다.
- 공개 API에서는 REST 우세: RPC의 장점에도 불구하고, REST는 단순함과 접근성 덕분에 공개 API에서 주로 사용됩니다. RPC는 조직 내부, 특히 데이터센터 내 통신에 주로 쓰입니다.

즉, RPC는 내부 서비스 통신에 역할을 유지하며, REST는 접근성과 생태계 지원 덕분에 공개 API 개발을 주도합니다.

**RPC에서의 데이터 인코딩 및 진화:**

RPC 시스템에서는 클라이언트와 서버가 독립적으로 업데이트될 수 있으므로 진화 가능성이 중요합니다. 일반적으로 서버가 클라이언트보다 먼저 업데이트되므로, 요청의 하위 호환성과 응답의 상위 호환성이 필요합니다.

- Thrift, gRPC, Avro RPC: 각 인코딩 포맷의 호환성 규칙을 따르며, Thrift, Protocol Buffers, Avro 스키마 기반으로 진화가 가능합니다.
- SOAP: XML 스키마가 SOAP 요청/응답을 정의하며, 진화가 가능하나 복잡함이 따릅니다.
- RESTful API: 응답은 주로 JSON, 요청은 URI/form 인코딩을 사용합니다. 호환 가능한 변경은 선택적 요청 파라미터나 새 응답 필드 추가 등입니다. JSON은 공식 스키마가 없어 신중함이 필요합니다.

조직 간 RPC 시스템에서는 호환성 유지가 어려우며, 서비스 제공자는 호환성 깨지는 변경이 불가피할 때 여러 API 버전을 동시에 지원하기도 합니다. <br>
API 버전 관리 방식은 다양합니다. RESTful API는 URL에 버전 번호를 포함하거나 HTTP Accept 헤더를 활용할 수 있습니다. API 키 기반 서비스는 관리 인터페이스에서 클라이언트가 원하는 버전을 지정할 수 있습니다.

### 메시지 전달 방식

메시지 전달 방식은 RPC와 데이터베이스 사이의 다리를 놓아, 프로세스 간 **비동기** 통신을 가능하게 합니다. 주요 특징은 다음과 같습니다.

- **저지연 전달**: 메시지는 RPC처럼 빠르게 프로세스에 전달됩니다.
- **중간 메시지 브로커**: 메시지는 브로커에 일시 저장되어, 신뢰성 버퍼링, 자동 재전송, 송신자/수신자 분리, 브로드캐스트 지원 등 이점이 있습니다.
- **비동기 통신**: RPC와 달리, 메시지 전달은 일반적으로 일방향이며 즉각적인 응답이 없어 확장성과 반응성이 높습니다.

결국, 메시지 전달 방식은 프로세스 간 robust하고 유연한 통신 방법을 제공합니다.

**메시지 브로커:**

과거에는 TIBCO, IBM WebSphere 같은 상용 솔루션이 주도했으나, 최근에는 RabbitMQ, ActiveMQ, Kafka 등 오픈소스 플랫폼이 대세입니다. 메시지 브로커는 프로세스 간 메시지 저장 및 전달을 담당합니다. <br>
프로세스는 이름이 지정된 큐나 토픽에 메시지를 보내고, 브로커는 이를 구독자나 소비자에게 전달합니다. 여러 생산자와 소비자가 동일 토픽에서 상호작용할 수 있어, 견고한 통신이 가능합니다. <br>
토픽은 일방향 데이터 흐름을 지원하지만, 소비자가 다른 토픽이나 응답 큐에 메시지를 게시해 RPC와 유사한 요청/응답 흐름도 구현할 수 있습니다. <br>
메시지 브로커는 데이터 모델에 중립적이며, 메시지를 메타데이터가 포함된 바이트 시퀀스로 처리해 인코딩 포맷의 유연성을 제공합니다. 단, 메시지를 재게시할 때 알려지지 않은 필드가 손실되지 않도록 주의해야 합니다.

**분산 액터 프레임워크:**

분산 액터 프레임워크는 액터 모델(동시성 프로그래밍 패러다임)을 확장해, 액터가 비동기 메시지로 통신하도록 합니다. <br>
분산 환경에서는 액터가 여러 노드에 걸쳐 있으며, 노드 위치와 상관없이 동일한 메시지 전달 방식을 사용합니다. <br>
RPC와 비교하면, 액터 모델은 메시지 손실 가능성을 기본적으로 가정하여 네트워크 상황에 더 잘 맞습니다. 네트워크 지연이 늘어나긴 하지만, 액터 모델은 로컬/원격 통신의 차이를 최소화합니다.

이 프레임워크들은 메시지 브로커와 액터 프로그래밍을 결합하지만, 액터 기반 애플리케이션 업그레이드 시 상위/하위 호환성 고려가 필요합니다. 세 가지 대표 프레임워크의 인코딩 방식은 다음과 같습니다.

- **Akka**: 주로 Java 직렬화를 사용하며, 호환성 기능이 부족합니다. Protocol Buffers 등으로 대체하면 롤링 업그레이드가 가능합니다.
- **Orleans**: 커스텀 인코딩 포맷을 사용해 버전 업그레이드 시 새로운 클러스터 구축이 필요합니다. 커스텀 직렬화 플러그인으로 해결할 수 있습니다.
- **Erlang OTP**: 높은 가용성을 갖추었지만 스키마 변경에는 어려움이 있습니다. 롤링 업그레이드는 가능하지만 신중한 계획이 필요하며, 실험적 데이터 타입(예: map) 도입이 업그레이드에 도움을 줄 수 있습니다.



